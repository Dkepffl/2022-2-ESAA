{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyZEJbsWWr4IKGA7urc8YY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dkepffl/2022-2-ESAA/blob/main/Assignment/Assignment221125_Keras1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PART 03 케라스(Keras)**"
      ],
      "metadata": {
        "id": "5v8sAWMXhNE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **01 딥러닝 준비**\n"
      ],
      "metadata": {
        "id": "vwkBs3P0hR8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **1-1 주요 용어**"
      ],
      "metadata": {
        "id": "SZ_3BNOGhntz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **1-1-1 하이퍼파라미터(hyper-parameter)**\n",
        "- 하이퍼파라미터는 딥러닝을 포함하여 머신러닝 모델을 훈련할 때 사용자가 직접 설정해주는 설정 값이다.\n",
        "- 사용자가 어떠한 값을 설정하느냐에 따라 모델의 성능 및 결과가 달라져, 하이퍼파라미터를 설정하는 것은 매우 중요하다. \n",
        "- 사용자가 별도로 설정하지 않으면, 기본값이 자동 적용된다.\n",
        "- 하이퍼파라미터 튜닝 : 하이퍼파라미터의 값을 조절하는 행위\n",
        "- 딥러닝 프로젝트 초기에는 튜닝에 많은 시간을 투자하는 것보다 마지막 단계에 진행하는 것을 추천한다.\n",
        "\n",
        "##### **1-1-2 과소적합 vs. 과대적합(underfitting vs. overfitting)**\n",
        "- 훈련용 데이터를 반복해서 학습하면 모델의 (학습 데이터에서의) 성능이 사람의 예측 성능을 뛰어 넘을 수도 있다. \n",
        "- 그러나 예측할 데이터의 분포가 학습 데이터와 다르거나 학습 데이터가 편향된 데이터였다면 모델의 **예측 성능이 현저히 저하**된다.\n",
        "- **과소적합** : 모델이 충분히 학습되지 않아 예측 성능이 떨어지는 경우\n",
        "- **과대적합** : 학습 데이터를 지나치게 반복 학습하여, 과하게 적합된 상태. 훈련 데이터에 존재하는 노이즈까지 모델에 반영되어, 예측 데이터에서의 성능이 크게 떨어진다.\n",
        "- 이를 해결하기 위해, 훈련 데이터를 잘 구성하고, 훈련 데이터의 일부를 검증 데이터로 활용하여, 검증 성능이 가장 좋은 구간을 최종 모델을 결정한다.\n",
        "\n",
        "##### **1-1-3 에포크(epoch)**\n",
        "- 에포크(epoch) : 딥러닝 모델이 반복 훈련을 할 때 데이터셋을 전부 학습에 사용하는 1회의 훈련 루프(loop)\n",
        "- 사전에 설정된 최대 epoch 횟수까지 반복적으로 훈련한다.\n",
        "\n",
        "##### **1-1-4 손실함수(loss function)**\n",
        "- **손실 함수** : 예측 값과 정답 값의 차이, 즉 오차(Error)\n",
        "- 딥러닝 모델에 적용하는 손실함수는 사용자가 정의해야 한다.\n",
        "- 이진 분류의 경우, `binary_crossentropy` 손실함수를 사용한다. 이는 출력츠으이 활성화 함수가 'sigmoid'인 경우를 말한다.\n",
        "- 다중 분류의 경우, `categorical_crossentropy` 손실함수를 사용하며, 다중 분류의 대상이 되는 클래스가 원-핫 벡터인 경우 사용한다. 그렇지 않다면(예 : 0, 1, 2, 3, $\\cdots$) `sparse_categorical_crossentropy` 손실함수를 사용한다. 출력함수로는 softmax를 이용한다.\n",
        "- 회귀 모델의 경우, MSE나 MAE, Huber 등을 이용한다.\n",
        "- 다음과 같이 손실함수를 지정하여 사용한다.\n",
        "```python\n",
        "import tensorflow as tf\n",
        "# 클래스 형태로 지정\n",
        "tf.keras.losses.BinaryCrossentropy()\n",
        "# 함수 형태로 지정\n",
        "tf.keras. losses.binary_crossentropy\n",
        "```"
      ],
      "metadata": {
        "id": "dBrKcShEm8Ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **1-1-5 경사 하강법(gradient descent)**\n",
        "- **경사하강법** : 딥러닝 모델 내부의 가중치(weight)에 대한 미분 값을 구하고 목적 함수 값이 낮아지는 방향으로 차감하면서 결국 최소 함수 값을 갖도록 하는 방법이다.\n",
        "- 경사하강법을 넘파이(NumPy)로 직접 구현해보자.\n",
        "  1. 손실 함수를 적용한다.\n",
        "  2. 단순선형회귀 수식이 주어졌을 때, 손실함수를 최소로 하는 w와 b를 경사하강법으로 구하는 과정을 구현한다.\n",
        "  3. 샘플 데이터셋을 생성하는 함수를 정의하고, 임의의 w와 b 값을 지정하여 주어진 x에 대한 y 값을 생성한다. y 값을 생성할 때 약간의 노이즈를 추가한다."
      ],
      "metadata": {
        "id": "unX9rm97vAOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 샘플에 활용할 데이터셋 생성 함수\n",
        "def make_linear(w=0.5, b=0.8, size=50, noise=1.0):\n",
        "    x = np.random.rand(size)\n",
        "    y = w * x + b\n",
        "    noise = np.random.uniform(-abs(noise), abs(noise), size=y.shape) # 약간의 노이즈 추가\n",
        "    yy = y + noise\n",
        "\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(x, y, color='r', label=f'y = {w}*x + {b}')\n",
        "    plt.scatter(x, yy, label='data')\n",
        "    plt.legend(fontsize=20)\n",
        "    plt.show()\n",
        "    print(f'w: {w}, b: {b}')\n",
        "    return x, yy"
      ],
      "metadata": {
        "id": "QnhpSfnsvBvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 데이터셋 생성\n",
        "x, y = make_linear(w=0.3, b=0.5, size=100, noise=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "Qn3kZ5bbvPLX",
        "outputId": "44adaa5c-fcb7-4ddb-8475-808b6d07f5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w: 0.3, b: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이제 경사하강법 알고리즘의 핵심인 w와 b에 대한 그래디언트를 구하는 부분을 구현하자.\n",
        "- 손실함수를 w, b에 대한 각각의 편미분 값을 구한 뒤 학습률 계수를 곱하여 이전의 w, b로부터 차감한다."
      ],
      "metadata": {
        "id": "83DXaKvEvUsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 반복 횟수\n",
        "num_epoch = 1000\n",
        "\n",
        "# 학습율 (learning_rate)\n",
        "learning_rate = 0.005\n",
        "\n",
        "# 에러 기록\n",
        "errors = []\n",
        "\n",
        "# random 한 값으로 w, b를 초기화 합니다.\n",
        "w = np.random.uniform(low=0.0, high=1.0)\n",
        "b = np.random.uniform(low=0.0, high=1.0)\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    # Hypothesis 정의\n",
        "    y_hat = w * x + b\n",
        "    \n",
        "    # Loss Function 정의\n",
        "    error = 0.5*((y_hat - y) ** 2).sum()\n",
        "    if error < 0.005:\n",
        "        break\n",
        "    # Gradient 미분 계산\n",
        "    w = w - learning_rate * ((y_hat - y) * x).sum()\n",
        "    b = b - learning_rate * (y_hat - y).sum()\n",
        "    \n",
        "    errors.append(error)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(\"{0:2} w = {1:.5f}, b = {2:.5f} error = {3:.5f}\".format(epoch, w, b, error))\n",
        "    \n",
        "print(\"----\" * 15)\n",
        "print(\"{0:2} w = {1:.1f}, b = {2:.1f} error = {3:.5f}\".format(epoch, w, b, error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pcPfWCKvp5q",
        "outputId": "1bb09d0f-12c0-4c1b-9881-8db0058e12c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0 w = 0.69265, b = 0.24165 error = 1.32577\n",
            " 5 w = 0.64535, b = 0.30528 error = 0.55506\n",
            "10 w = 0.59208, b = 0.33542 error = 0.39707\n",
            "15 w = 0.54697, b = 0.36077 error = 0.28418\n",
            "20 w = 0.50884, b = 0.38219 error = 0.20351\n",
            "25 w = 0.47661, b = 0.40030 error = 0.14587\n",
            "30 w = 0.44937, b = 0.41561 error = 0.10468\n",
            "35 w = 0.42633, b = 0.42856 error = 0.07525\n",
            "40 w = 0.40686, b = 0.43950 error = 0.05422\n",
            "45 w = 0.39041, b = 0.44874 error = 0.03919\n",
            "50 w = 0.37649, b = 0.45656 error = 0.02845\n",
            "55 w = 0.36473, b = 0.46317 error = 0.02078\n",
            "60 w = 0.35479, b = 0.46876 error = 0.01529\n",
            "65 w = 0.34639, b = 0.47348 error = 0.01137\n",
            "70 w = 0.33929, b = 0.47747 error = 0.00857\n",
            "75 w = 0.33328, b = 0.48084 error = 0.00657\n",
            "80 w = 0.32820, b = 0.48370 error = 0.00514\n",
            "------------------------------------------------------------\n",
            "81 w = 0.3, b = 0.5 error = 0.00491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(errors)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Error')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "SJfYp60WvyqP",
        "outputId": "4a2e85e8-c6a3-4703-be22-37114170789a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **1-2 딥러닝 프로세스**\n",
        "- 데이터 로드\n",
        "- 데이터 전처리(피처 가공, 피처 선택, 피처 추출)\n",
        "- 데이터 분할\n",
        "- 모델 생성 및 컴파일\n",
        "- 훈련\n",
        "- 검증\n",
        "- 하이퍼파라미터 튜닝 후 모델 생성 및 컴파일 단계부터 검증 단계까지 다시 진행\n",
        "- 예측"
      ],
      "metadata": {
        "id": "aPOZSPhNhrSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **1-2-1 데이터 전처리**\n",
        "- 모델 훈련 전 데이터를 가공하는 단계\n",
        "- 데이터셋의 종류와 문제 유형에 따라 방법이 다양하다.\n",
        "- 배열의 차원을 변경하거나 스케일을 조정할 수 있다.\n",
        "\n",
        "##### **1-2-2 모델 생성**\n",
        "- 모델의 구조를 정의하고 생성하는 단계\n",
        "- 순차적 구조의 모델은 Sequential API로, 다중 입력 및 출력 등 복잡한 구조를 갖는 모델은 Functional API 혹은 Model Subclassing 방법으로 구현할 수 있다.\n",
        "\n",
        "##### **1-2-3 모델 컴파일**\n",
        "- 생성된 모델 훈련에 사용한 손실함수, 옵티마이저, 평가지표 등을 정의\n",
        "- 모델 인스턴스에 `compile()` 메소드를 적용하고 위의 속성 값을 설정한다.\n",
        "\n",
        "##### **1-2-4 모델 훈련**\n",
        "- 모델을 훈련하는 단계\n",
        "- `fit()` 함수에 모델 훈련에 필요한 훈련 데이터셋, 검증 데이터셋을 입력하고, epoch, batch 크기 및 콜백 함수 등을 지정한다.\n",
        "\n",
        "##### **1-2-5 모델 검증**\n",
        "- 훈련이 완료된 모델을 검증하는 단계\n",
        "- 모델을 훈련할 때 **사용하지 않은** 검증 데이터셋을 모델에 입력하고 평가 지표를 계산한다.\n",
        "- 검증 결과를 바탕으로 다시 모델 생성 단계로 돌아가 모델을 수정하고 재평가하는 과정을 목표 성능에 도달할 때까지 반복한다.\n",
        "\n",
        "##### **1-2-6 모델 예측**\n",
        "- 훈련과 검증이 완료된 모델로 테스트셋에 대해 예측"
      ],
      "metadata": {
        "id": "QgCYmGntwZBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **02 단순 신경망 훈련**"
      ],
      "metadata": {
        "id": "0E4fjDUvhXXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **2-1 선형 회귀**\n",
        "- 회귀 분석 : 하나 이상의 독립 변수들이 종속 변수에 미치는 영향을 추정하는 통계 기법\n",
        "- 그 중 단순선형회귀(simple linear regression) 모형은 하나의 X가 Y에 미치는 영향을 추정하며, 1차 함수 관계로 나타낼 수 있다.\n",
        "$$y = ax + b$$\n",
        "- 텐서플로 케라스를 활용하여 딥러닝으로 단순선형회귀 모델을 직접 만들어보자"
      ],
      "metadata": {
        "id": "XVgPuK79htI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **2-2 뉴런(Neuron)**\n",
        "- 뉴런은 인공 신경망 모델을 구성하는 하나의 신경을 의미한다.\n",
        "- 노드(node)라고도 한다.\n",
        "- 신경망은 여러 개의 레이어로 이루어져 있으며 1개의 레이어는 1개 이상의 뉴런으로 구성된다."
      ],
      "metadata": {
        "id": "e06fm00phvXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **2-3 Dense 레이어**\n",
        "- Dense 레이어는 심층 신경망 모델을 구성하는 가장 기본 레이어이다.\n",
        "- 각 레이어와 레이어 사이에 모든 뉴런이 연결되어 있어 완전 연결층(Fully Connected Layer)라고 부른다.\n",
        "- 다음과 같이 노드의 개수와 활성화 함수를 지정하여 사용할 수 있다.\n",
        "```python\n",
        "import tensorflow as tf\n",
        "# 10개의 노드로 이루어진 Dense 레이어\n",
        "tf.keras.layers.Dense(10)\n",
        "# ReLU 활성화 함수 적용\n",
        "tf.keras.layers.Dense(10, activation='relu')\n",
        "```"
      ],
      "metadata": {
        "id": "0ZA5qiOKhy0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **2-4 데이터셋 만들기**\n",
        "- 넘파이의 `arrange()` 메소드를 이용하여 5개의 순차적인 x 데이터를 생성하고 이를 1차 함수인 $y= 3x + 2$에 대입하여 y 데이터 5개를 생성한다."
      ],
      "metadata": {
        "id": "86lQmzbHh3Ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 데이터셋 생성\n",
        "x = np.arange(1, 6)\n",
        "\n",
        "# y = 3x + 2\n",
        "y = 3 * x + 2"
      ],
      "metadata": {
        "id": "Vw5FIO2i3mf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mDZ4CYC3s00",
        "outputId": "00651043-6663-4d9e-ccda-be6b92aa69a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4 5]\n",
            "[ 5  8 11 14 17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 생성한 데이터를 그래프로 시각화해보자."
      ],
      "metadata": {
        "id": "ESv-pg_h3xVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화\n",
        "plt.plot(x, y)\n",
        "plt.title('y = 3x + 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "d1UwpM3R31R1",
        "outputId": "e5cf1ad9-16ae-49a7-8e1f-fcc0313d3eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **2-5 Sequential API**\n",
        "- 앞에서 언급한 것처럼 간단한 구조의 딥러닝 모델은 케라스의 Sequantial API를 이용하여 만들 수 있다.\n",
        "- **Sequantial API** : 층을 이어 붙이듯 순서에 맞게 일렬로 연결하는 방식"
      ],
      "metadata": {
        "id": "j2AA1TvNh5-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **2-5-1 모델 구조**\n",
        "1. **리스트형 정의**\n",
        "  - Sequential 클래스 함수에 파이썬 리스트 형태로 여러 개의 층을 입력한다.\n",
        "  - 앞에 위치한 층부터 연산을 먼저 처리하고 순차적으로 다음 층의 연산을 수행한다.\n",
        "  ```python\n",
        "  import tensorflow as tf\n",
        "  # 리스트형\n",
        "  model = tf.keras.Sequential([\n",
        "          tf.keras.layers.Dense(10),\n",
        "          tf.keras.layers.Dense(5),\n",
        "          tf.keras.layers.Dense(1)\n",
        "          ])\n",
        "  ```\n",
        "2. **add 함수로 레이어 추가**\n",
        "  - Sequential 클래스 객체 생성 후, 모델 객체에 층을 추가하는 방식\n",
        "  - `add()` 메소드는 1개의 층을 추가할 수 있다.\n",
        "  ```python\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(10))\n",
        "  model.add(tf.keras.layers.Dense(5))\n",
        "  model.add(tf.keras.layers.Dense(1))\n",
        "  ```\n",
        "\n",
        "##### **2-5-2 단순선형회귀 모델 정의**\n",
        "- 단순선형회귀에서 입력 변수는 1개이기 때문에, Dense 레이어 생성 시 `input_shape=[1]`로 지정한다.\n",
        "- 1개의 뉴런을 가지는 Dense 레이어는 1개의 출력값을 가지므로, 출력값은 y에 대한 모델의 예측 값이다."
      ],
      "metadata": {
        "id": "mFtw30L44Mde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        " \n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1, input_shape=[1])\n",
        "        ])"
      ],
      "metadata": {
        "id": "sjsTRHgx6KzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **2-6 모델 요약**\n",
        "- Sequential API로 모델을 만들었따면 `model.summary()`로 모델의 요약을 확인할 수 있다.\n",
        "- 모델의 구조, 층별 노드의 개수 등을 확인할 수 있다."
      ],
      "metadata": {
        "id": "3y9DwrsDh89f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk2QVpfm6SEC",
        "outputId": "5b587381-75a4-4a36-916d-bf36ed16a9ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **2-7 컴파일**\n",
        "- 모델의 훈련 과정에서 적용할 옵티마이저(optimizer), 손실 함수, 그리고 평가지표 등을 정의한다.\n",
        "- 클래스 인스턴스로 지정할 경우, 학습률, 모멘텀 등의 하이퍼 파라미터를 사용자가 직접 지정할 수도 있다."
      ],
      "metadata": {
        "id": "we_lxxeLh-6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 긴 문자열 지정\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error', \n",
        "              metrics=['mean_squared_error', 'mean_absolute_error'])"
      ],
      "metadata": {
        "id": "9zLkIfYt6izo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 짧은 문자열 지정\n",
        "model.compile(optimizer='sgd', loss='mse', metrics=['mse', 'mae'])"
      ],
      "metadata": {
        "id": "o46bv-pL6l43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 인스턴스 지정\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.005), \n",
        "              loss=tf.keras.losses.MeanAbsoluteError(), \n",
        "              metrics=[tf.keras.metrics.MeanAbsoluteError(), \n",
        "                       tf.keras.metrics.MeanSquaredError()\n",
        "                       ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsyWsge26oG_",
        "outputId": "370145de-2633-4870-b2e9-cac90e0f5b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 옵티마이저는 확률적 경사하강법, 손실함수는 MSE, 평가 지표는 MAE로 지정하여 모델을 훈련시켜보자."
      ],
      "metadata": {
        "id": "w5G7UQff6uQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 컴파일\n",
        "model.compile(optimizer='sgd', loss='mse', metrics=['mae'])"
      ],
      "metadata": {
        "id": "mkIbq7-V60P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **2-8 훈련**\n",
        "- 생성된 모델 인스턴스에 `fit()` 메소드를 적용하면, 데이터를 입력하여 모델을 훈련할 수 있다.\n",
        "- **'모델을 훈련한다.'** : 가중치를 업데이트"
      ],
      "metadata": {
        "id": "_AIs6pOMiAZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JVs_fow7Cec",
        "outputId": "8fed90d5-4ee1-44d0-f7a0-2c9ae24bb905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 546ms/step - loss: 121.6208 - mae: 10.3091\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 70.9725 - mae: 7.9149\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 41.4566 - mae: 6.0871\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 24.2555 - mae: 4.6916\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.2309 - mae: 3.6262\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7c2bad0810>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 5 epoch의 훈련이 끝난 후, loss는 14.2309, mae는 3.6262를 기록했따.\n",
        "- 위 학습에서는 모델의 예측 오차가 점점 줄어드는 것을 보아, 과소 적합되었을 가능성이 있다.\n",
        "- 이번에는 epoch을 1200으로 지정하여 충분히 훈련시킨다."
      ],
      "metadata": {
        "id": "xt7UBnf87IUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1, input_shape=[1])\n",
        "        ])\n",
        "\n",
        "# 컴파일\n",
        "model.compile(optimizer='sgd', loss='mse', metrics=['mae'])\n",
        "\n",
        "# 훈련\n",
        "history = model.fit(x, y, epochs=1200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mt8fQgt7cUq",
        "outputId": "693d9bde-0484-4711-ba53-18207d944d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1200\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 172.4930 - mae: 12.2184\n",
            "Epoch 2/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 100.5923 - mae: 9.3660\n",
            "Epoch 3/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 58.6917 - mae: 7.1884\n",
            "Epoch 4/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 34.2736 - mae: 5.5259\n",
            "Epoch 5/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 20.0435 - mae: 4.2567\n",
            "Epoch 6/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.7504 - mae: 3.2876\n",
            "Epoch 7/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9171 - mae: 2.5478\n",
            "Epoch 8/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.1000 - mae: 1.9828\n",
            "Epoch 9/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4579 - mae: 1.5514\n",
            "Epoch 10/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5005 - mae: 1.2220\n",
            "Epoch 11/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9421 - mae: 0.9704\n",
            "Epoch 12/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6162 - mae: 0.7782\n",
            "Epoch 13/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4259 - mae: 0.6313\n",
            "Epoch 14/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3145 - mae: 0.5191\n",
            "Epoch 15/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2492 - mae: 0.4333\n",
            "Epoch 16/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2106 - mae: 0.3760\n",
            "Epoch 17/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1877 - mae: 0.3573\n",
            "Epoch 18/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1740 - mae: 0.3428\n",
            "Epoch 19/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1655 - mae: 0.3315\n",
            "Epoch 20/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1601 - mae: 0.3251\n",
            "Epoch 21/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1566 - mae: 0.3268\n",
            "Epoch 22/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1541 - mae: 0.3278\n",
            "Epoch 23/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1522 - mae: 0.3283\n",
            "Epoch 24/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1507 - mae: 0.3284\n",
            "Epoch 25/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1494 - mae: 0.3282\n",
            "Epoch 26/1200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1482 - mae: 0.3278\n",
            "Epoch 27/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1471 - mae: 0.3273\n",
            "Epoch 28/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1461 - mae: 0.3266\n",
            "Epoch 29/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1450 - mae: 0.3258\n",
            "Epoch 30/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1440 - mae: 0.3249\n",
            "Epoch 31/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1431 - mae: 0.3240\n",
            "Epoch 32/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1421 - mae: 0.3231\n",
            "Epoch 33/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1411 - mae: 0.3221\n",
            "Epoch 34/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1402 - mae: 0.3211\n",
            "Epoch 35/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1392 - mae: 0.3200\n",
            "Epoch 36/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1383 - mae: 0.3190\n",
            "Epoch 37/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1373 - mae: 0.3180\n",
            "Epoch 38/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1364 - mae: 0.3169\n",
            "Epoch 39/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1355 - mae: 0.3159\n",
            "Epoch 40/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1346 - mae: 0.3148\n",
            "Epoch 41/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1337 - mae: 0.3138\n",
            "Epoch 42/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1328 - mae: 0.3127\n",
            "Epoch 43/1200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1319 - mae: 0.3117\n",
            "Epoch 44/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1310 - mae: 0.3106\n",
            "Epoch 45/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1301 - mae: 0.3096\n",
            "Epoch 46/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1292 - mae: 0.3085\n",
            "Epoch 47/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1283 - mae: 0.3075\n",
            "Epoch 48/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1275 - mae: 0.3064\n",
            "Epoch 49/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1266 - mae: 0.3054\n",
            "Epoch 50/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1258 - mae: 0.3044\n",
            "Epoch 51/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1249 - mae: 0.3034\n",
            "Epoch 52/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1241 - mae: 0.3023\n",
            "Epoch 53/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1232 - mae: 0.3013\n",
            "Epoch 54/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1224 - mae: 0.3003\n",
            "Epoch 55/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1216 - mae: 0.2993\n",
            "Epoch 56/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1208 - mae: 0.2983\n",
            "Epoch 57/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1199 - mae: 0.2973\n",
            "Epoch 58/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1191 - mae: 0.2963\n",
            "Epoch 59/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1183 - mae: 0.2952\n",
            "Epoch 60/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1175 - mae: 0.2943\n",
            "Epoch 61/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1167 - mae: 0.2933\n",
            "Epoch 62/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1159 - mae: 0.2923\n",
            "Epoch 63/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1152 - mae: 0.2913\n",
            "Epoch 64/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1144 - mae: 0.2903\n",
            "Epoch 65/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1136 - mae: 0.2893\n",
            "Epoch 66/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1128 - mae: 0.2883\n",
            "Epoch 67/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1121 - mae: 0.2874\n",
            "Epoch 68/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1113 - mae: 0.2864\n",
            "Epoch 69/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1106 - mae: 0.2854\n",
            "Epoch 70/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1098 - mae: 0.2845\n",
            "Epoch 71/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1091 - mae: 0.2835\n",
            "Epoch 72/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1084 - mae: 0.2825\n",
            "Epoch 73/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1076 - mae: 0.2816\n",
            "Epoch 74/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1069 - mae: 0.2806\n",
            "Epoch 75/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1062 - mae: 0.2797\n",
            "Epoch 76/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1055 - mae: 0.2787\n",
            "Epoch 77/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1047 - mae: 0.2778\n",
            "Epoch 78/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1040 - mae: 0.2768\n",
            "Epoch 79/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1033 - mae: 0.2759\n",
            "Epoch 80/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1026 - mae: 0.2750\n",
            "Epoch 81/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1019 - mae: 0.2741\n",
            "Epoch 82/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1013 - mae: 0.2731\n",
            "Epoch 83/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1006 - mae: 0.2722\n",
            "Epoch 84/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0999 - mae: 0.2713\n",
            "Epoch 85/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0992 - mae: 0.2704\n",
            "Epoch 86/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0985 - mae: 0.2694\n",
            "Epoch 87/1200\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0979 - mae: 0.2685\n",
            "Epoch 88/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0972 - mae: 0.2676\n",
            "Epoch 89/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0966 - mae: 0.2667\n",
            "Epoch 90/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0959 - mae: 0.2658\n",
            "Epoch 91/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0953 - mae: 0.2649\n",
            "Epoch 92/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0946 - mae: 0.2640\n",
            "Epoch 93/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0940 - mae: 0.2631\n",
            "Epoch 94/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0934 - mae: 0.2622\n",
            "Epoch 95/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0927 - mae: 0.2614\n",
            "Epoch 96/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0921 - mae: 0.2605\n",
            "Epoch 97/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0915 - mae: 0.2596\n",
            "Epoch 98/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0909 - mae: 0.2587\n",
            "Epoch 99/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0902 - mae: 0.2578\n",
            "Epoch 100/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0896 - mae: 0.2570\n",
            "Epoch 101/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0890 - mae: 0.2561\n",
            "Epoch 102/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0884 - mae: 0.2552\n",
            "Epoch 103/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0878 - mae: 0.2544\n",
            "Epoch 104/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0872 - mae: 0.2535\n",
            "Epoch 105/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0866 - mae: 0.2527\n",
            "Epoch 106/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0861 - mae: 0.2518\n",
            "Epoch 107/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0855 - mae: 0.2510\n",
            "Epoch 108/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0849 - mae: 0.2501\n",
            "Epoch 109/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0843 - mae: 0.2493\n",
            "Epoch 110/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0838 - mae: 0.2484\n",
            "Epoch 111/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0832 - mae: 0.2476\n",
            "Epoch 112/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0826 - mae: 0.2467\n",
            "Epoch 113/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0821 - mae: 0.2459\n",
            "Epoch 114/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0815 - mae: 0.2451\n",
            "Epoch 115/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0810 - mae: 0.2442\n",
            "Epoch 116/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0804 - mae: 0.2434\n",
            "Epoch 117/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0799 - mae: 0.2426\n",
            "Epoch 118/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0793 - mae: 0.2418\n",
            "Epoch 119/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0788 - mae: 0.2410\n",
            "Epoch 120/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0783 - mae: 0.2401\n",
            "Epoch 121/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0777 - mae: 0.2393\n",
            "Epoch 122/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0772 - mae: 0.2385\n",
            "Epoch 123/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0767 - mae: 0.2377\n",
            "Epoch 124/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0762 - mae: 0.2369\n",
            "Epoch 125/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0757 - mae: 0.2361\n",
            "Epoch 126/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0752 - mae: 0.2353\n",
            "Epoch 127/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0747 - mae: 0.2345\n",
            "Epoch 128/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0741 - mae: 0.2337\n",
            "Epoch 129/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0736 - mae: 0.2329\n",
            "Epoch 130/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0732 - mae: 0.2321\n",
            "Epoch 131/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0727 - mae: 0.2314\n",
            "Epoch 132/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0722 - mae: 0.2306\n",
            "Epoch 133/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0717 - mae: 0.2298\n",
            "Epoch 134/1200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0712 - mae: 0.2290\n",
            "Epoch 135/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0707 - mae: 0.2282\n",
            "Epoch 136/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0702 - mae: 0.2275\n",
            "Epoch 137/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0698 - mae: 0.2267\n",
            "Epoch 138/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0693 - mae: 0.2259\n",
            "Epoch 139/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0688 - mae: 0.2252\n",
            "Epoch 140/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0684 - mae: 0.2244\n",
            "Epoch 141/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0679 - mae: 0.2237\n",
            "Epoch 142/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0674 - mae: 0.2229\n",
            "Epoch 143/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0670 - mae: 0.2221\n",
            "Epoch 144/1200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0665 - mae: 0.2214\n",
            "Epoch 145/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0661 - mae: 0.2206\n",
            "Epoch 146/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0656 - mae: 0.2199\n",
            "Epoch 147/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0652 - mae: 0.2192\n",
            "Epoch 148/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0648 - mae: 0.2184\n",
            "Epoch 149/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0643 - mae: 0.2177\n",
            "Epoch 150/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0639 - mae: 0.2169\n",
            "Epoch 151/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0635 - mae: 0.2162\n",
            "Epoch 152/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0630 - mae: 0.2155\n",
            "Epoch 153/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0626 - mae: 0.2147\n",
            "Epoch 154/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0622 - mae: 0.2140\n",
            "Epoch 155/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0618 - mae: 0.2133\n",
            "Epoch 156/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0613 - mae: 0.2126\n",
            "Epoch 157/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0609 - mae: 0.2119\n",
            "Epoch 158/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0605 - mae: 0.2111\n",
            "Epoch 159/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0601 - mae: 0.2104\n",
            "Epoch 160/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0597 - mae: 0.2097\n",
            "Epoch 161/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0593 - mae: 0.2090\n",
            "Epoch 162/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0589 - mae: 0.2083\n",
            "Epoch 163/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0585 - mae: 0.2076\n",
            "Epoch 164/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0581 - mae: 0.2069\n",
            "Epoch 165/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0577 - mae: 0.2062\n",
            "Epoch 166/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0573 - mae: 0.2055\n",
            "Epoch 167/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0569 - mae: 0.2048\n",
            "Epoch 168/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0566 - mae: 0.2041\n",
            "Epoch 169/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0562 - mae: 0.2034\n",
            "Epoch 170/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0558 - mae: 0.2027\n",
            "Epoch 171/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0554 - mae: 0.2020\n",
            "Epoch 172/1200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0550 - mae: 0.2014\n",
            "Epoch 173/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0547 - mae: 0.2007\n",
            "Epoch 174/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0543 - mae: 0.2000\n",
            "Epoch 175/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0539 - mae: 0.1993\n",
            "Epoch 176/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0536 - mae: 0.1987\n",
            "Epoch 177/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0532 - mae: 0.1980\n",
            "Epoch 178/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0528 - mae: 0.1973\n",
            "Epoch 179/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0525 - mae: 0.1966\n",
            "Epoch 180/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0521 - mae: 0.1960\n",
            "Epoch 181/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0518 - mae: 0.1953\n",
            "Epoch 182/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0514 - mae: 0.1947\n",
            "Epoch 183/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0511 - mae: 0.1940\n",
            "Epoch 184/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0507 - mae: 0.1933\n",
            "Epoch 185/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0504 - mae: 0.1927\n",
            "Epoch 186/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0501 - mae: 0.1920\n",
            "Epoch 187/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0497 - mae: 0.1914\n",
            "Epoch 188/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0494 - mae: 0.1907\n",
            "Epoch 189/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0491 - mae: 0.1901\n",
            "Epoch 190/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0487 - mae: 0.1895\n",
            "Epoch 191/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0484 - mae: 0.1888\n",
            "Epoch 192/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0481 - mae: 0.1882\n",
            "Epoch 193/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0477 - mae: 0.1875\n",
            "Epoch 194/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0474 - mae: 0.1869\n",
            "Epoch 195/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0471 - mae: 0.1863\n",
            "Epoch 196/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0468 - mae: 0.1856\n",
            "Epoch 197/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0465 - mae: 0.1850\n",
            "Epoch 198/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0462 - mae: 0.1844\n",
            "Epoch 199/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0458 - mae: 0.1838\n",
            "Epoch 200/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0455 - mae: 0.1831\n",
            "Epoch 201/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0452 - mae: 0.1825\n",
            "Epoch 202/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0449 - mae: 0.1819\n",
            "Epoch 203/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0446 - mae: 0.1813\n",
            "Epoch 204/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0443 - mae: 0.1807\n",
            "Epoch 205/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0440 - mae: 0.1801\n",
            "Epoch 206/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0437 - mae: 0.1795\n",
            "Epoch 207/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0434 - mae: 0.1789\n",
            "Epoch 208/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0431 - mae: 0.1783\n",
            "Epoch 209/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0428 - mae: 0.1776\n",
            "Epoch 210/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0425 - mae: 0.1770\n",
            "Epoch 211/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0423 - mae: 0.1765\n",
            "Epoch 212/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0420 - mae: 0.1759\n",
            "Epoch 213/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0417 - mae: 0.1753\n",
            "Epoch 214/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0414 - mae: 0.1747\n",
            "Epoch 215/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0411 - mae: 0.1741\n",
            "Epoch 216/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 0.1735\n",
            "Epoch 217/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0406 - mae: 0.1729\n",
            "Epoch 218/1200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0403 - mae: 0.1723\n",
            "Epoch 219/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0400 - mae: 0.1717\n",
            "Epoch 220/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0398 - mae: 0.1712\n",
            "Epoch 221/1200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0395 - mae: 0.1706\n",
            "Epoch 222/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0392 - mae: 0.1700\n",
            "Epoch 223/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0390 - mae: 0.1694\n",
            "Epoch 224/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0387 - mae: 0.1689\n",
            "Epoch 225/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0384 - mae: 0.1683\n",
            "Epoch 226/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0382 - mae: 0.1677\n",
            "Epoch 227/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0379 - mae: 0.1671\n",
            "Epoch 228/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0377 - mae: 0.1666\n",
            "Epoch 229/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0374 - mae: 0.1660\n",
            "Epoch 230/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0372 - mae: 0.1655\n",
            "Epoch 231/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0369 - mae: 0.1649\n",
            "Epoch 232/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0367 - mae: 0.1643\n",
            "Epoch 233/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0364 - mae: 0.1638\n",
            "Epoch 234/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0362 - mae: 0.1632\n",
            "Epoch 235/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0359 - mae: 0.1627\n",
            "Epoch 236/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0357 - mae: 0.1621\n",
            "Epoch 237/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0354 - mae: 0.1616\n",
            "Epoch 238/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0352 - mae: 0.1610\n",
            "Epoch 239/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0350 - mae: 0.1605\n",
            "Epoch 240/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0347 - mae: 0.1599\n",
            "Epoch 241/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0345 - mae: 0.1594\n",
            "Epoch 242/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0343 - mae: 0.1589\n",
            "Epoch 243/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0340 - mae: 0.1583\n",
            "Epoch 244/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0338 - mae: 0.1578\n",
            "Epoch 245/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0336 - mae: 0.1573\n",
            "Epoch 246/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0333 - mae: 0.1567\n",
            "Epoch 247/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0331 - mae: 0.1562\n",
            "Epoch 248/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0329 - mae: 0.1557\n",
            "Epoch 249/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0327 - mae: 0.1551\n",
            "Epoch 250/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0325 - mae: 0.1546\n",
            "Epoch 251/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0322 - mae: 0.1541\n",
            "Epoch 252/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0320 - mae: 0.1536\n",
            "Epoch 253/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0318 - mae: 0.1531\n",
            "Epoch 254/1200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0316 - mae: 0.1525\n",
            "Epoch 255/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0314 - mae: 0.1520\n",
            "Epoch 256/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0312 - mae: 0.1515\n",
            "Epoch 257/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0309 - mae: 0.1510\n",
            "Epoch 258/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0307 - mae: 0.1505\n",
            "Epoch 259/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0305 - mae: 0.1500\n",
            "Epoch 260/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0303 - mae: 0.1495\n",
            "Epoch 261/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0301 - mae: 0.1490\n",
            "Epoch 262/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0299 - mae: 0.1485\n",
            "Epoch 263/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0297 - mae: 0.1480\n",
            "Epoch 264/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0295 - mae: 0.1475\n",
            "Epoch 265/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0293 - mae: 0.1470\n",
            "Epoch 266/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0291 - mae: 0.1465\n",
            "Epoch 267/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0289 - mae: 0.1460\n",
            "Epoch 268/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0287 - mae: 0.1455\n",
            "Epoch 269/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0285 - mae: 0.1450\n",
            "Epoch 270/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0283 - mae: 0.1445\n",
            "Epoch 271/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0281 - mae: 0.1440\n",
            "Epoch 272/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0280 - mae: 0.1435\n",
            "Epoch 273/1200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0278 - mae: 0.1430\n",
            "Epoch 274/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0276 - mae: 0.1425\n",
            "Epoch 275/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0274 - mae: 0.1421\n",
            "Epoch 276/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0272 - mae: 0.1416\n",
            "Epoch 277/1200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0270 - mae: 0.1411\n",
            "Epoch 278/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0268 - mae: 0.1406\n",
            "Epoch 279/1200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0267 - mae: 0.1402\n",
            "Epoch 280/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0265 - mae: 0.1397\n",
            "Epoch 281/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0263 - mae: 0.1392\n",
            "Epoch 282/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0261 - mae: 0.1387\n",
            "Epoch 283/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0260 - mae: 0.1383\n",
            "Epoch 284/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0258 - mae: 0.1378\n",
            "Epoch 285/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0256 - mae: 0.1373\n",
            "Epoch 286/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0254 - mae: 0.1369\n",
            "Epoch 287/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0253 - mae: 0.1364\n",
            "Epoch 288/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0251 - mae: 0.1359\n",
            "Epoch 289/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0249 - mae: 0.1355\n",
            "Epoch 290/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0247 - mae: 0.1350\n",
            "Epoch 291/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0246 - mae: 0.1346\n",
            "Epoch 292/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0244 - mae: 0.1341\n",
            "Epoch 293/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0243 - mae: 0.1337\n",
            "Epoch 294/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0241 - mae: 0.1332\n",
            "Epoch 295/1200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0239 - mae: 0.1328\n",
            "Epoch 296/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0238 - mae: 0.1323\n",
            "Epoch 297/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0236 - mae: 0.1319\n",
            "Epoch 298/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0234 - mae: 0.1314\n",
            "Epoch 299/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0233 - mae: 0.1310\n",
            "Epoch 300/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0231 - mae: 0.1305\n",
            "Epoch 301/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0230 - mae: 0.1301\n",
            "Epoch 302/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0228 - mae: 0.1297\n",
            "Epoch 303/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0227 - mae: 0.1292\n",
            "Epoch 304/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0225 - mae: 0.1288\n",
            "Epoch 305/1200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0224 - mae: 0.1283\n",
            "Epoch 306/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0222 - mae: 0.1279\n",
            "Epoch 307/1200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0221 - mae: 0.1275\n",
            "Epoch 308/1200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0219 - mae: 0.1270\n",
            "Epoch 309/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0218 - mae: 0.1266\n",
            "Epoch 310/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0216 - mae: 0.1262\n",
            "Epoch 311/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0215 - mae: 0.1258\n",
            "Epoch 312/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0213 - mae: 0.1253\n",
            "Epoch 313/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0212 - mae: 0.1249\n",
            "Epoch 314/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0210 - mae: 0.1245\n",
            "Epoch 315/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0209 - mae: 0.1241\n",
            "Epoch 316/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0208 - mae: 0.1236\n",
            "Epoch 317/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0206 - mae: 0.1232\n",
            "Epoch 318/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0205 - mae: 0.1228\n",
            "Epoch 319/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0203 - mae: 0.1224\n",
            "Epoch 320/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0202 - mae: 0.1220\n",
            "Epoch 321/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0201 - mae: 0.1216\n",
            "Epoch 322/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0199 - mae: 0.1212\n",
            "Epoch 323/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0198 - mae: 0.1208\n",
            "Epoch 324/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0197 - mae: 0.1203\n",
            "Epoch 325/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0195 - mae: 0.1199\n",
            "Epoch 326/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0194 - mae: 0.1195\n",
            "Epoch 327/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0193 - mae: 0.1191\n",
            "Epoch 328/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0191 - mae: 0.1187\n",
            "Epoch 329/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0190 - mae: 0.1183\n",
            "Epoch 330/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0189 - mae: 0.1179\n",
            "Epoch 331/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0187 - mae: 0.1175\n",
            "Epoch 332/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0186 - mae: 0.1171\n",
            "Epoch 333/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0185 - mae: 0.1167\n",
            "Epoch 334/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0184 - mae: 0.1163\n",
            "Epoch 335/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0182 - mae: 0.1159\n",
            "Epoch 336/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0181 - mae: 0.1156\n",
            "Epoch 337/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0180 - mae: 0.1152\n",
            "Epoch 338/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0179 - mae: 0.1148\n",
            "Epoch 339/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0178 - mae: 0.1144\n",
            "Epoch 340/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0176 - mae: 0.1140\n",
            "Epoch 341/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0175 - mae: 0.1136\n",
            "Epoch 342/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0174 - mae: 0.1132\n",
            "Epoch 343/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0173 - mae: 0.1128\n",
            "Epoch 344/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0172 - mae: 0.1125\n",
            "Epoch 345/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0171 - mae: 0.1121\n",
            "Epoch 346/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0169 - mae: 0.1117\n",
            "Epoch 347/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0168 - mae: 0.1113\n",
            "Epoch 348/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0167 - mae: 0.1109\n",
            "Epoch 349/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0166 - mae: 0.1106\n",
            "Epoch 350/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0165 - mae: 0.1102\n",
            "Epoch 351/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0164 - mae: 0.1098\n",
            "Epoch 352/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0163 - mae: 0.1095\n",
            "Epoch 353/1200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0162 - mae: 0.1091\n",
            "Epoch 354/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0160 - mae: 0.1087\n",
            "Epoch 355/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0159 - mae: 0.1083\n",
            "Epoch 356/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0158 - mae: 0.1080\n",
            "Epoch 357/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0157 - mae: 0.1076\n",
            "Epoch 358/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0156 - mae: 0.1073\n",
            "Epoch 359/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0155 - mae: 0.1069\n",
            "Epoch 360/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0154 - mae: 0.1065\n",
            "Epoch 361/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0153 - mae: 0.1062\n",
            "Epoch 362/1200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0152 - mae: 0.1058\n",
            "Epoch 363/1200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0151 - mae: 0.1055\n",
            "Epoch 364/1200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0150 - mae: 0.1051\n",
            "Epoch 365/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0149 - mae: 0.1047\n",
            "Epoch 366/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0148 - mae: 0.1044\n",
            "Epoch 367/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0147 - mae: 0.1040\n",
            "Epoch 368/1200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0146 - mae: 0.1037\n",
            "Epoch 369/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0145 - mae: 0.1033\n",
            "Epoch 370/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0144 - mae: 0.1030\n",
            "Epoch 371/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0143 - mae: 0.1026\n",
            "Epoch 372/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0142 - mae: 0.1023\n",
            "Epoch 373/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0141 - mae: 0.1019\n",
            "Epoch 374/1200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0140 - mae: 0.1016\n",
            "Epoch 375/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0139 - mae: 0.1013\n",
            "Epoch 376/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0138 - mae: 0.1009\n",
            "Epoch 377/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0137 - mae: 0.1006\n",
            "Epoch 378/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0136 - mae: 0.1002\n",
            "Epoch 379/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0135 - mae: 0.0999\n",
            "Epoch 380/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0135 - mae: 0.0996\n",
            "Epoch 381/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0134 - mae: 0.0992\n",
            "Epoch 382/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0133 - mae: 0.0989\n",
            "Epoch 383/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0132 - mae: 0.0985\n",
            "Epoch 384/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0131 - mae: 0.0982\n",
            "Epoch 385/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0130 - mae: 0.0979\n",
            "Epoch 386/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.0976\n",
            "Epoch 387/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0128 - mae: 0.0972\n",
            "Epoch 388/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0127 - mae: 0.0969\n",
            "Epoch 389/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.0966\n",
            "Epoch 390/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0126 - mae: 0.0962\n",
            "Epoch 391/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.0959\n",
            "Epoch 392/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0956\n",
            "Epoch 393/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0953\n",
            "Epoch 394/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0949\n",
            "Epoch 395/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0946\n",
            "Epoch 396/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.0943\n",
            "Epoch 397/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0940\n",
            "Epoch 398/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0119 - mae: 0.0937\n",
            "Epoch 399/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0118 - mae: 0.0933\n",
            "Epoch 400/1200\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0117 - mae: 0.0930\n",
            "Epoch 401/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0117 - mae: 0.0927\n",
            "Epoch 402/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0116 - mae: 0.0924\n",
            "Epoch 403/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0115 - mae: 0.0921\n",
            "Epoch 404/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0114 - mae: 0.0918\n",
            "Epoch 405/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0114 - mae: 0.0915\n",
            "Epoch 406/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.0912\n",
            "Epoch 407/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0112 - mae: 0.0909\n",
            "Epoch 408/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0111 - mae: 0.0905\n",
            "Epoch 409/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0111 - mae: 0.0902\n",
            "Epoch 410/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0110 - mae: 0.0899\n",
            "Epoch 411/1200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0109 - mae: 0.0896\n",
            "Epoch 412/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0108 - mae: 0.0893\n",
            "Epoch 413/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.0890\n",
            "Epoch 414/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0107 - mae: 0.0887\n",
            "Epoch 415/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.0884\n",
            "Epoch 416/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0881\n",
            "Epoch 417/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.0878\n",
            "Epoch 418/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.0875\n",
            "Epoch 419/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0872\n",
            "Epoch 420/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.0869\n",
            "Epoch 421/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.0866\n",
            "Epoch 422/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0864\n",
            "Epoch 423/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0861\n",
            "Epoch 424/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0858\n",
            "Epoch 425/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0855\n",
            "Epoch 426/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.0852\n",
            "Epoch 427/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0849\n",
            "Epoch 428/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.0846\n",
            "Epoch 429/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0843\n",
            "Epoch 430/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0096 - mae: 0.0840\n",
            "Epoch 431/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.0838\n",
            "Epoch 432/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.0835\n",
            "Epoch 433/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0832\n",
            "Epoch 434/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0093 - mae: 0.0829\n",
            "Epoch 435/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0093 - mae: 0.0826\n",
            "Epoch 436/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0092 - mae: 0.0824\n",
            "Epoch 437/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0091 - mae: 0.0821\n",
            "Epoch 438/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0091 - mae: 0.0818\n",
            "Epoch 439/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0090 - mae: 0.0815\n",
            "Epoch 440/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0090 - mae: 0.0812\n",
            "Epoch 441/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0089 - mae: 0.0810\n",
            "Epoch 442/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0088 - mae: 0.0807\n",
            "Epoch 443/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0088 - mae: 0.0804\n",
            "Epoch 444/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0087 - mae: 0.0802\n",
            "Epoch 445/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0087 - mae: 0.0799\n",
            "Epoch 446/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0796\n",
            "Epoch 447/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0085 - mae: 0.0793\n",
            "Epoch 448/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.0791\n",
            "Epoch 449/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0084 - mae: 0.0788\n",
            "Epoch 450/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0785\n",
            "Epoch 451/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0783\n",
            "Epoch 452/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0780\n",
            "Epoch 453/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0082 - mae: 0.0777\n",
            "Epoch 454/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0775\n",
            "Epoch 455/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0772\n",
            "Epoch 456/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0770\n",
            "Epoch 457/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0767\n",
            "Epoch 458/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0764\n",
            "Epoch 459/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0762\n",
            "Epoch 460/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0759\n",
            "Epoch 461/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0757\n",
            "Epoch 462/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0077 - mae: 0.0754\n",
            "Epoch 463/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0077 - mae: 0.0752\n",
            "Epoch 464/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0076 - mae: 0.0749\n",
            "Epoch 465/1200\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.0076 - mae: 0.0747\n",
            "Epoch 466/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0075 - mae: 0.0744\n",
            "Epoch 467/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0075 - mae: 0.0741\n",
            "Epoch 468/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0074 - mae: 0.0739\n",
            "Epoch 469/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0736\n",
            "Epoch 470/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0073 - mae: 0.0734\n",
            "Epoch 471/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0073 - mae: 0.0731\n",
            "Epoch 472/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0729\n",
            "Epoch 473/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0727\n",
            "Epoch 474/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0724\n",
            "Epoch 475/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0071 - mae: 0.0722\n",
            "Epoch 476/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0070 - mae: 0.0719\n",
            "Epoch 477/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0070 - mae: 0.0717\n",
            "Epoch 478/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0714\n",
            "Epoch 479/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0712\n",
            "Epoch 480/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0068 - mae: 0.0710\n",
            "Epoch 481/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0707\n",
            "Epoch 482/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0067 - mae: 0.0705\n",
            "Epoch 483/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0067 - mae: 0.0702\n",
            "Epoch 484/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0700\n",
            "Epoch 485/1200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0066 - mae: 0.0698\n",
            "Epoch 486/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0695\n",
            "Epoch 487/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0065 - mae: 0.0693\n",
            "Epoch 488/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0065 - mae: 0.0691\n",
            "Epoch 489/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0064 - mae: 0.0688\n",
            "Epoch 490/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0064 - mae: 0.0686\n",
            "Epoch 491/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0063 - mae: 0.0684\n",
            "Epoch 492/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0681\n",
            "Epoch 493/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0063 - mae: 0.0679\n",
            "Epoch 494/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0062 - mae: 0.0677\n",
            "Epoch 495/1200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - mae: 0.0674\n",
            "Epoch 496/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0672\n",
            "Epoch 497/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0670\n",
            "Epoch 498/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0668\n",
            "Epoch 499/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0665\n",
            "Epoch 500/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0060 - mae: 0.0663\n",
            "Epoch 501/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0059 - mae: 0.0661\n",
            "Epoch 502/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0059 - mae: 0.0659\n",
            "Epoch 503/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0058 - mae: 0.0656\n",
            "Epoch 504/1200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0058 - mae: 0.0654\n",
            "Epoch 505/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0058 - mae: 0.0652\n",
            "Epoch 506/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0057 - mae: 0.0650\n",
            "Epoch 507/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0057 - mae: 0.0648\n",
            "Epoch 508/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0057 - mae: 0.0645\n",
            "Epoch 509/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0056 - mae: 0.0643\n",
            "Epoch 510/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0056 - mae: 0.0641\n",
            "Epoch 511/1200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0055 - mae: 0.0639\n",
            "Epoch 512/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0055 - mae: 0.0637\n",
            "Epoch 513/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0055 - mae: 0.0635\n",
            "Epoch 514/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0054 - mae: 0.0632\n",
            "Epoch 515/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0054 - mae: 0.0630\n",
            "Epoch 516/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0054 - mae: 0.0628\n",
            "Epoch 517/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0053 - mae: 0.0626\n",
            "Epoch 518/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0624\n",
            "Epoch 519/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0622\n",
            "Epoch 520/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0052 - mae: 0.0620\n",
            "Epoch 521/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0618\n",
            "Epoch 522/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0051 - mae: 0.0615\n",
            "Epoch 523/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0613\n",
            "Epoch 524/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0611\n",
            "Epoch 525/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0609\n",
            "Epoch 526/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0607\n",
            "Epoch 527/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0050 - mae: 0.0605\n",
            "Epoch 528/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0049 - mae: 0.0603\n",
            "Epoch 529/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0601\n",
            "Epoch 530/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0049 - mae: 0.0599\n",
            "Epoch 531/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0048 - mae: 0.0597\n",
            "Epoch 532/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0048 - mae: 0.0595\n",
            "Epoch 533/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0593\n",
            "Epoch 534/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0591\n",
            "Epoch 535/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0589\n",
            "Epoch 536/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0047 - mae: 0.0587\n",
            "Epoch 537/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0046 - mae: 0.0585\n",
            "Epoch 538/1200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0046 - mae: 0.0583\n",
            "Epoch 539/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0046 - mae: 0.0581\n",
            "Epoch 540/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0046 - mae: 0.0579\n",
            "Epoch 541/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0577\n",
            "Epoch 542/1200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0575\n",
            "Epoch 543/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0573\n",
            "Epoch 544/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0571\n",
            "Epoch 545/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0569\n",
            "Epoch 546/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0567\n",
            "Epoch 547/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0565\n",
            "Epoch 548/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0564\n",
            "Epoch 549/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0562\n",
            "Epoch 550/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0560\n",
            "Epoch 551/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0558\n",
            "Epoch 552/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0556\n",
            "Epoch 553/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0554\n",
            "Epoch 554/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0552\n",
            "Epoch 555/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0041 - mae: 0.0550\n",
            "Epoch 556/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0041 - mae: 0.0549\n",
            "Epoch 557/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0041 - mae: 0.0547\n",
            "Epoch 558/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0545\n",
            "Epoch 559/1200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - mae: 0.0543\n",
            "Epoch 560/1200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0040 - mae: 0.0541\n",
            "Epoch 561/1200\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.0039 - mae: 0.0539\n",
            "Epoch 562/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0039 - mae: 0.0537\n",
            "Epoch 563/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - mae: 0.0536\n",
            "Epoch 564/1200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0039 - mae: 0.0534\n",
            "Epoch 565/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0532\n",
            "Epoch 566/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0038 - mae: 0.0530\n",
            "Epoch 567/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0038 - mae: 0.0528\n",
            "Epoch 568/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0038 - mae: 0.0527\n",
            "Epoch 569/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0037 - mae: 0.0525\n",
            "Epoch 570/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0037 - mae: 0.0523\n",
            "Epoch 571/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0037 - mae: 0.0521\n",
            "Epoch 572/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0037 - mae: 0.0520\n",
            "Epoch 573/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0036 - mae: 0.0518\n",
            "Epoch 574/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0036 - mae: 0.0516\n",
            "Epoch 575/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0036 - mae: 0.0514\n",
            "Epoch 576/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0036 - mae: 0.0513\n",
            "Epoch 577/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - mae: 0.0511\n",
            "Epoch 578/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0035 - mae: 0.0509\n",
            "Epoch 579/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0035 - mae: 0.0507\n",
            "Epoch 580/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0035 - mae: 0.0506\n",
            "Epoch 581/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0034 - mae: 0.0504\n",
            "Epoch 582/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0034 - mae: 0.0502\n",
            "Epoch 583/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0034 - mae: 0.0501\n",
            "Epoch 584/1200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0034 - mae: 0.0499\n",
            "Epoch 585/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - mae: 0.0497\n",
            "Epoch 586/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0033 - mae: 0.0496\n",
            "Epoch 587/1200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - mae: 0.0494\n",
            "Epoch 588/1200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0033 - mae: 0.0492\n",
            "Epoch 589/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0033 - mae: 0.0491\n",
            "Epoch 590/1200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - mae: 0.0489\n",
            "Epoch 591/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0032 - mae: 0.0487\n",
            "Epoch 592/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0032 - mae: 0.0486\n",
            "Epoch 593/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0032 - mae: 0.0484\n",
            "Epoch 594/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0032 - mae: 0.0482\n",
            "Epoch 595/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0481\n",
            "Epoch 596/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0479\n",
            "Epoch 597/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0031 - mae: 0.0477\n",
            "Epoch 598/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0031 - mae: 0.0476\n",
            "Epoch 599/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0031 - mae: 0.0474\n",
            "Epoch 600/1200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mae: 0.0473\n",
            "Epoch 601/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0030 - mae: 0.0471\n",
            "Epoch 602/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0469\n",
            "Epoch 603/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0468\n",
            "Epoch 604/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0466\n",
            "Epoch 605/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0029 - mae: 0.0465\n",
            "Epoch 606/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0029 - mae: 0.0463\n",
            "Epoch 607/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0029 - mae: 0.0462\n",
            "Epoch 608/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0460\n",
            "Epoch 609/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0029 - mae: 0.0458\n",
            "Epoch 610/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0457\n",
            "Epoch 611/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0028 - mae: 0.0455\n",
            "Epoch 612/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0028 - mae: 0.0454\n",
            "Epoch 613/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0028 - mae: 0.0452\n",
            "Epoch 614/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0451\n",
            "Epoch 615/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0027 - mae: 0.0449\n",
            "Epoch 616/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0448\n",
            "Epoch 617/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0027 - mae: 0.0446\n",
            "Epoch 618/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0027 - mae: 0.0445\n",
            "Epoch 619/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0027 - mae: 0.0443\n",
            "Epoch 620/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0026 - mae: 0.0442\n",
            "Epoch 621/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0026 - mae: 0.0440\n",
            "Epoch 622/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0026 - mae: 0.0439\n",
            "Epoch 623/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0026 - mae: 0.0437\n",
            "Epoch 624/1200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0026 - mae: 0.0436\n",
            "Epoch 625/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0026 - mae: 0.0434\n",
            "Epoch 626/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0025 - mae: 0.0433\n",
            "Epoch 627/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0025 - mae: 0.0431\n",
            "Epoch 628/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0025 - mae: 0.0430\n",
            "Epoch 629/1200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0025 - mae: 0.0428\n",
            "Epoch 630/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0025 - mae: 0.0427\n",
            "Epoch 631/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0025 - mae: 0.0425\n",
            "Epoch 632/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0024 - mae: 0.0424\n",
            "Epoch 633/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0024 - mae: 0.0423\n",
            "Epoch 634/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0024 - mae: 0.0421\n",
            "Epoch 635/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0024 - mae: 0.0420\n",
            "Epoch 636/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0024 - mae: 0.0418\n",
            "Epoch 637/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0024 - mae: 0.0417\n",
            "Epoch 638/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0023 - mae: 0.0416\n",
            "Epoch 639/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0414\n",
            "Epoch 640/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0023 - mae: 0.0413\n",
            "Epoch 641/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0411\n",
            "Epoch 642/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0023 - mae: 0.0410\n",
            "Epoch 643/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0409\n",
            "Epoch 644/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0407\n",
            "Epoch 645/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0022 - mae: 0.0406\n",
            "Epoch 646/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0404\n",
            "Epoch 647/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0022 - mae: 0.0403\n",
            "Epoch 648/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0022 - mae: 0.0402\n",
            "Epoch 649/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0022 - mae: 0.0400\n",
            "Epoch 650/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0399\n",
            "Epoch 651/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0021 - mae: 0.0398\n",
            "Epoch 652/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0021 - mae: 0.0396\n",
            "Epoch 653/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0021 - mae: 0.0395\n",
            "Epoch 654/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0021 - mae: 0.0394\n",
            "Epoch 655/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0021 - mae: 0.0392\n",
            "Epoch 656/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0021 - mae: 0.0391\n",
            "Epoch 657/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0021 - mae: 0.0390\n",
            "Epoch 658/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0020 - mae: 0.0388\n",
            "Epoch 659/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0020 - mae: 0.0387\n",
            "Epoch 660/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0020 - mae: 0.0386\n",
            "Epoch 661/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0384\n",
            "Epoch 662/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0383\n",
            "Epoch 663/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0020 - mae: 0.0382\n",
            "Epoch 664/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0020 - mae: 0.0380\n",
            "Epoch 665/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0020 - mae: 0.0379\n",
            "Epoch 666/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0019 - mae: 0.0378\n",
            "Epoch 667/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0019 - mae: 0.0377\n",
            "Epoch 668/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0375\n",
            "Epoch 669/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0374\n",
            "Epoch 670/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0373\n",
            "Epoch 671/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0019 - mae: 0.0372\n",
            "Epoch 672/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0370\n",
            "Epoch 673/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0018 - mae: 0.0369\n",
            "Epoch 674/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0018 - mae: 0.0368\n",
            "Epoch 675/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0018 - mae: 0.0367\n",
            "Epoch 676/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0018 - mae: 0.0365\n",
            "Epoch 677/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0018 - mae: 0.0364\n",
            "Epoch 678/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0018 - mae: 0.0363\n",
            "Epoch 679/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - mae: 0.0362\n",
            "Epoch 680/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - mae: 0.0360\n",
            "Epoch 681/1200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0018 - mae: 0.0359\n",
            "Epoch 682/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - mae: 0.0358\n",
            "Epoch 683/1200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - mae: 0.0357\n",
            "Epoch 684/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0356\n",
            "Epoch 685/1200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0017 - mae: 0.0354\n",
            "Epoch 686/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0017 - mae: 0.0353\n",
            "Epoch 687/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0017 - mae: 0.0352\n",
            "Epoch 688/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0017 - mae: 0.0351\n",
            "Epoch 689/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - mae: 0.0350\n",
            "Epoch 690/1200\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0016 - mae: 0.0348\n",
            "Epoch 691/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0016 - mae: 0.0347\n",
            "Epoch 692/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0016 - mae: 0.0346\n",
            "Epoch 693/1200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0016 - mae: 0.0345\n",
            "Epoch 694/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0016 - mae: 0.0344\n",
            "Epoch 695/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0016 - mae: 0.0343\n",
            "Epoch 696/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0016 - mae: 0.0341\n",
            "Epoch 697/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0016 - mae: 0.0340\n",
            "Epoch 698/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0016 - mae: 0.0339\n",
            "Epoch 699/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0016 - mae: 0.0338\n",
            "Epoch 700/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0015 - mae: 0.0337\n",
            "Epoch 701/1200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - mae: 0.0336\n",
            "Epoch 702/1200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - mae: 0.0335\n",
            "Epoch 703/1200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0015 - mae: 0.0333\n",
            "Epoch 704/1200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0015 - mae: 0.0332\n",
            "Epoch 705/1200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0015 - mae: 0.0331\n",
            "Epoch 706/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - mae: 0.0330\n",
            "Epoch 707/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - mae: 0.0329\n",
            "Epoch 708/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - mae: 0.0328\n",
            "Epoch 709/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0014 - mae: 0.0327\n",
            "Epoch 710/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0014 - mae: 0.0326\n",
            "Epoch 711/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0014 - mae: 0.0324\n",
            "Epoch 712/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0014 - mae: 0.0323\n",
            "Epoch 713/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0014 - mae: 0.0322\n",
            "Epoch 714/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0014 - mae: 0.0321\n",
            "Epoch 715/1200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0014 - mae: 0.0320\n",
            "Epoch 716/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0014 - mae: 0.0319\n",
            "Epoch 717/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0014 - mae: 0.0318\n",
            "Epoch 718/1200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0014 - mae: 0.0317\n",
            "Epoch 719/1200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0014 - mae: 0.0316\n",
            "Epoch 720/1200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0013 - mae: 0.0315\n",
            "Epoch 721/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0013 - mae: 0.0314\n",
            "Epoch 722/1200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0013 - mae: 0.0313\n",
            "Epoch 723/1200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0013 - mae: 0.0312\n",
            "Epoch 724/1200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0013 - mae: 0.0311\n",
            "Epoch 725/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - mae: 0.0309\n",
            "Epoch 726/1200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - mae: 0.0308\n",
            "Epoch 727/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0013 - mae: 0.0307\n",
            "Epoch 728/1200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - mae: 0.0306\n",
            "Epoch 729/1200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0013 - mae: 0.0305\n",
            "Epoch 730/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0013 - mae: 0.0304\n",
            "Epoch 731/1200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0012 - mae: 0.0303\n",
            "Epoch 732/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0302\n",
            "Epoch 733/1200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0012 - mae: 0.0301\n",
            "Epoch 734/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0012 - mae: 0.0300\n",
            "Epoch 735/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0299\n",
            "Epoch 736/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0012 - mae: 0.0298\n",
            "Epoch 737/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0297\n",
            "Epoch 738/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0012 - mae: 0.0296\n",
            "Epoch 739/1200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0012 - mae: 0.0295\n",
            "Epoch 740/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0012 - mae: 0.0294\n",
            "Epoch 741/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0293\n",
            "Epoch 742/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0012 - mae: 0.0292\n",
            "Epoch 743/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0012 - mae: 0.0291\n",
            "Epoch 744/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0290\n",
            "Epoch 745/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0289\n",
            "Epoch 746/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0011 - mae: 0.0288\n",
            "Epoch 747/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0011 - mae: 0.0287\n",
            "Epoch 748/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - mae: 0.0286\n",
            "Epoch 749/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0285\n",
            "Epoch 750/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0284\n",
            "Epoch 751/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0283\n",
            "Epoch 752/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0011 - mae: 0.0282\n",
            "Epoch 753/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0011 - mae: 0.0281\n",
            "Epoch 754/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0011 - mae: 0.0281\n",
            "Epoch 755/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0280\n",
            "Epoch 756/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0011 - mae: 0.0279\n",
            "Epoch 757/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0010 - mae: 0.0278\n",
            "Epoch 758/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0010 - mae: 0.0277\n",
            "Epoch 759/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0010 - mae: 0.0276\n",
            "Epoch 760/1200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0010 - mae: 0.0275\n",
            "Epoch 761/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0010 - mae: 0.0274\n",
            "Epoch 762/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0010 - mae: 0.0273\n",
            "Epoch 763/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0272\n",
            "Epoch 764/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.9820e-04 - mae: 0.0271\n",
            "Epoch 765/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9148e-04 - mae: 0.0270\n",
            "Epoch 766/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.8476e-04 - mae: 0.0269\n",
            "Epoch 767/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.7814e-04 - mae: 0.0268\n",
            "Epoch 768/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7153e-04 - mae: 0.0268\n",
            "Epoch 769/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.6496e-04 - mae: 0.0267\n",
            "Epoch 770/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5847e-04 - mae: 0.0266\n",
            "Epoch 771/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5199e-04 - mae: 0.0265\n",
            "Epoch 772/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4557e-04 - mae: 0.0264\n",
            "Epoch 773/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.3917e-04 - mae: 0.0263\n",
            "Epoch 774/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.3286e-04 - mae: 0.0262\n",
            "Epoch 775/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.2654e-04 - mae: 0.0261\n",
            "Epoch 776/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.2030e-04 - mae: 0.0260\n",
            "Epoch 777/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1408e-04 - mae: 0.0260\n",
            "Epoch 778/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0790e-04 - mae: 0.0259\n",
            "Epoch 779/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.0176e-04 - mae: 0.0258\n",
            "Epoch 780/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9569e-04 - mae: 0.0257\n",
            "Epoch 781/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.8965e-04 - mae: 0.0256\n",
            "Epoch 782/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.8362e-04 - mae: 0.0255\n",
            "Epoch 783/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7768e-04 - mae: 0.0254\n",
            "Epoch 784/1200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.7175e-04 - mae: 0.0253\n",
            "Epoch 785/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6587e-04 - mae: 0.0253\n",
            "Epoch 786/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.6003e-04 - mae: 0.0252\n",
            "Epoch 787/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.5419e-04 - mae: 0.0251\n",
            "Epoch 788/1200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.4844e-04 - mae: 0.0250\n",
            "Epoch 789/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4270e-04 - mae: 0.0249\n",
            "Epoch 790/1200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.3702e-04 - mae: 0.0248\n",
            "Epoch 791/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3138e-04 - mae: 0.0247\n",
            "Epoch 792/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.2576e-04 - mae: 0.0247\n",
            "Epoch 793/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.2019e-04 - mae: 0.0246\n",
            "Epoch 794/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.1465e-04 - mae: 0.0245\n",
            "Epoch 795/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.0915e-04 - mae: 0.0244\n",
            "Epoch 796/1200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 8.0370e-04 - mae: 0.0243\n",
            "Epoch 797/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.9825e-04 - mae: 0.0243\n",
            "Epoch 798/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.9288e-04 - mae: 0.0242\n",
            "Epoch 799/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.8751e-04 - mae: 0.0241\n",
            "Epoch 800/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.8222e-04 - mae: 0.0240\n",
            "Epoch 801/1200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.7693e-04 - mae: 0.0239\n",
            "Epoch 802/1200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 7.7168e-04 - mae: 0.0238\n",
            "Epoch 803/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.6647e-04 - mae: 0.0238\n",
            "Epoch 804/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.6130e-04 - mae: 0.0237\n",
            "Epoch 805/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.5616e-04 - mae: 0.0236\n",
            "Epoch 806/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5105e-04 - mae: 0.0235\n",
            "Epoch 807/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4600e-04 - mae: 0.0234\n",
            "Epoch 808/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4095e-04 - mae: 0.0234\n",
            "Epoch 809/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.3594e-04 - mae: 0.0233\n",
            "Epoch 810/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.3098e-04 - mae: 0.0232\n",
            "Epoch 811/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.2604e-04 - mae: 0.0231\n",
            "Epoch 812/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2114e-04 - mae: 0.0230\n",
            "Epoch 813/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1629e-04 - mae: 0.0230\n",
            "Epoch 814/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1144e-04 - mae: 0.0229\n",
            "Epoch 815/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.0664e-04 - mae: 0.0228\n",
            "Epoch 816/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0186e-04 - mae: 0.0227\n",
            "Epoch 817/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9713e-04 - mae: 0.0227\n",
            "Epoch 818/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9243e-04 - mae: 0.0226\n",
            "Epoch 819/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.8775e-04 - mae: 0.0225\n",
            "Epoch 820/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8311e-04 - mae: 0.0224\n",
            "Epoch 821/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.7850e-04 - mae: 0.0224\n",
            "Epoch 822/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.7391e-04 - mae: 0.0223\n",
            "Epoch 823/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.6937e-04 - mae: 0.0222\n",
            "Epoch 824/1200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.6484e-04 - mae: 0.0221\n",
            "Epoch 825/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.6037e-04 - mae: 0.0221\n",
            "Epoch 826/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.5590e-04 - mae: 0.0220\n",
            "Epoch 827/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5148e-04 - mae: 0.0219\n",
            "Epoch 828/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4707e-04 - mae: 0.0218\n",
            "Epoch 829/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4271e-04 - mae: 0.0218\n",
            "Epoch 830/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.3836e-04 - mae: 0.0217\n",
            "Epoch 831/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3407e-04 - mae: 0.0216\n",
            "Epoch 832/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.2977e-04 - mae: 0.0215\n",
            "Epoch 833/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.2552e-04 - mae: 0.0215\n",
            "Epoch 834/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.2131e-04 - mae: 0.0214\n",
            "Epoch 835/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.1711e-04 - mae: 0.0213\n",
            "Epoch 836/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.1295e-04 - mae: 0.0213\n",
            "Epoch 837/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.0880e-04 - mae: 0.0212\n",
            "Epoch 838/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0470e-04 - mae: 0.0211\n",
            "Epoch 839/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0062e-04 - mae: 0.0210\n",
            "Epoch 840/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9657e-04 - mae: 0.0210\n",
            "Epoch 841/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.9253e-04 - mae: 0.0209\n",
            "Epoch 842/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8853e-04 - mae: 0.0208\n",
            "Epoch 843/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8456e-04 - mae: 0.0208\n",
            "Epoch 844/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8062e-04 - mae: 0.0207\n",
            "Epoch 845/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7669e-04 - mae: 0.0206\n",
            "Epoch 846/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.7281e-04 - mae: 0.0205\n",
            "Epoch 847/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.6894e-04 - mae: 0.0205\n",
            "Epoch 848/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6511e-04 - mae: 0.0204\n",
            "Epoch 849/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.6127e-04 - mae: 0.0203\n",
            "Epoch 850/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5750e-04 - mae: 0.0203\n",
            "Epoch 851/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5373e-04 - mae: 0.0202\n",
            "Epoch 852/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4999e-04 - mae: 0.0201\n",
            "Epoch 853/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4628e-04 - mae: 0.0201\n",
            "Epoch 854/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4260e-04 - mae: 0.0200\n",
            "Epoch 855/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3892e-04 - mae: 0.0199\n",
            "Epoch 856/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.3529e-04 - mae: 0.0199\n",
            "Epoch 857/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.3168e-04 - mae: 0.0198\n",
            "Epoch 858/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2808e-04 - mae: 0.0197\n",
            "Epoch 859/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2452e-04 - mae: 0.0197\n",
            "Epoch 860/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2097e-04 - mae: 0.0196\n",
            "Epoch 861/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1747e-04 - mae: 0.0195\n",
            "Epoch 862/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.1398e-04 - mae: 0.0195\n",
            "Epoch 863/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.1051e-04 - mae: 0.0194\n",
            "Epoch 864/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 5.0707e-04 - mae: 0.0193\n",
            "Epoch 865/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.0365e-04 - mae: 0.0193\n",
            "Epoch 866/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0025e-04 - mae: 0.0192\n",
            "Epoch 867/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.9686e-04 - mae: 0.0191\n",
            "Epoch 868/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.9350e-04 - mae: 0.0191\n",
            "Epoch 869/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.9018e-04 - mae: 0.0190\n",
            "Epoch 870/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.8687e-04 - mae: 0.0189\n",
            "Epoch 871/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.8357e-04 - mae: 0.0189\n",
            "Epoch 872/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.8031e-04 - mae: 0.0188\n",
            "Epoch 873/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.7707e-04 - mae: 0.0187\n",
            "Epoch 874/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.7385e-04 - mae: 0.0187\n",
            "Epoch 875/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7065e-04 - mae: 0.0186\n",
            "Epoch 876/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.6747e-04 - mae: 0.0186\n",
            "Epoch 877/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.6432e-04 - mae: 0.0185\n",
            "Epoch 878/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.6120e-04 - mae: 0.0184\n",
            "Epoch 879/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5807e-04 - mae: 0.0184\n",
            "Epoch 880/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5498e-04 - mae: 0.0183\n",
            "Epoch 881/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5191e-04 - mae: 0.0182\n",
            "Epoch 882/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4885e-04 - mae: 0.0182\n",
            "Epoch 883/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4583e-04 - mae: 0.0181\n",
            "Epoch 884/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4282e-04 - mae: 0.0181\n",
            "Epoch 885/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3983e-04 - mae: 0.0180\n",
            "Epoch 886/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.3687e-04 - mae: 0.0179\n",
            "Epoch 887/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3392e-04 - mae: 0.0179\n",
            "Epoch 888/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.3098e-04 - mae: 0.0178\n",
            "Epoch 889/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2807e-04 - mae: 0.0178\n",
            "Epoch 890/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2517e-04 - mae: 0.0177\n",
            "Epoch 891/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2230e-04 - mae: 0.0176\n",
            "Epoch 892/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1945e-04 - mae: 0.0176\n",
            "Epoch 893/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.1664e-04 - mae: 0.0175\n",
            "Epoch 894/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.1381e-04 - mae: 0.0175\n",
            "Epoch 895/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1102e-04 - mae: 0.0174\n",
            "Epoch 896/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0826e-04 - mae: 0.0173\n",
            "Epoch 897/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0549e-04 - mae: 0.0173\n",
            "Epoch 898/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0275e-04 - mae: 0.0172\n",
            "Epoch 899/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0004e-04 - mae: 0.0172\n",
            "Epoch 900/1200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3.9733e-04 - mae: 0.0171\n",
            "Epoch 901/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9465e-04 - mae: 0.0171\n",
            "Epoch 902/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9198e-04 - mae: 0.0170\n",
            "Epoch 903/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.8935e-04 - mae: 0.0169\n",
            "Epoch 904/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8671e-04 - mae: 0.0169\n",
            "Epoch 905/1200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.8410e-04 - mae: 0.0168\n",
            "Epoch 906/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8150e-04 - mae: 0.0168\n",
            "Epoch 907/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7894e-04 - mae: 0.0167\n",
            "Epoch 908/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7638e-04 - mae: 0.0167\n",
            "Epoch 909/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7384e-04 - mae: 0.0166\n",
            "Epoch 910/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7131e-04 - mae: 0.0165\n",
            "Epoch 911/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6880e-04 - mae: 0.0165\n",
            "Epoch 912/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6632e-04 - mae: 0.0164\n",
            "Epoch 913/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6385e-04 - mae: 0.0164\n",
            "Epoch 914/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6139e-04 - mae: 0.0163\n",
            "Epoch 915/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5895e-04 - mae: 0.0163\n",
            "Epoch 916/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5653e-04 - mae: 0.0162\n",
            "Epoch 917/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5413e-04 - mae: 0.0162\n",
            "Epoch 918/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5174e-04 - mae: 0.0161\n",
            "Epoch 919/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4935e-04 - mae: 0.0160\n",
            "Epoch 920/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4699e-04 - mae: 0.0160\n",
            "Epoch 921/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4465e-04 - mae: 0.0159\n",
            "Epoch 922/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4233e-04 - mae: 0.0159\n",
            "Epoch 923/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4002e-04 - mae: 0.0158\n",
            "Epoch 924/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3772e-04 - mae: 0.0158\n",
            "Epoch 925/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3544e-04 - mae: 0.0157\n",
            "Epoch 926/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3317e-04 - mae: 0.0157\n",
            "Epoch 927/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3093e-04 - mae: 0.0156\n",
            "Epoch 928/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2869e-04 - mae: 0.0156\n",
            "Epoch 929/1200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 3.2648e-04 - mae: 0.0155\n",
            "Epoch 930/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2428e-04 - mae: 0.0155\n",
            "Epoch 931/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2208e-04 - mae: 0.0154\n",
            "Epoch 932/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1991e-04 - mae: 0.0154\n",
            "Epoch 933/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1776e-04 - mae: 0.0153\n",
            "Epoch 934/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.1560e-04 - mae: 0.0152\n",
            "Epoch 935/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.1348e-04 - mae: 0.0152\n",
            "Epoch 936/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.1135e-04 - mae: 0.0151\n",
            "Epoch 937/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.0926e-04 - mae: 0.0151\n",
            "Epoch 938/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.0716e-04 - mae: 0.0150\n",
            "Epoch 939/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0509e-04 - mae: 0.0150\n",
            "Epoch 940/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0303e-04 - mae: 0.0149\n",
            "Epoch 941/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0100e-04 - mae: 0.0149\n",
            "Epoch 942/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9897e-04 - mae: 0.0148\n",
            "Epoch 943/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9694e-04 - mae: 0.0148\n",
            "Epoch 944/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.9493e-04 - mae: 0.0147\n",
            "Epoch 945/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9295e-04 - mae: 0.0147\n",
            "Epoch 946/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9097e-04 - mae: 0.0146\n",
            "Epoch 947/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8901e-04 - mae: 0.0146\n",
            "Epoch 948/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8705e-04 - mae: 0.0145\n",
            "Epoch 949/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8511e-04 - mae: 0.0145\n",
            "Epoch 950/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8319e-04 - mae: 0.0144\n",
            "Epoch 951/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8129e-04 - mae: 0.0144\n",
            "Epoch 952/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7937e-04 - mae: 0.0143\n",
            "Epoch 953/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7749e-04 - mae: 0.0143\n",
            "Epoch 954/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7562e-04 - mae: 0.0142\n",
            "Epoch 955/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7377e-04 - mae: 0.0142\n",
            "Epoch 956/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7191e-04 - mae: 0.0142\n",
            "Epoch 957/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7008e-04 - mae: 0.0141\n",
            "Epoch 958/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6826e-04 - mae: 0.0141\n",
            "Epoch 959/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6644e-04 - mae: 0.0140\n",
            "Epoch 960/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6465e-04 - mae: 0.0140\n",
            "Epoch 961/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6286e-04 - mae: 0.0139\n",
            "Epoch 962/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6108e-04 - mae: 0.0139\n",
            "Epoch 963/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5933e-04 - mae: 0.0138\n",
            "Epoch 964/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.5758e-04 - mae: 0.0138\n",
            "Epoch 965/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5583e-04 - mae: 0.0137\n",
            "Epoch 966/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5411e-04 - mae: 0.0137\n",
            "Epoch 967/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5239e-04 - mae: 0.0136\n",
            "Epoch 968/1200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.5069e-04 - mae: 0.0136\n",
            "Epoch 969/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.4899e-04 - mae: 0.0135\n",
            "Epoch 970/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.4732e-04 - mae: 0.0135\n",
            "Epoch 971/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4565e-04 - mae: 0.0135\n",
            "Epoch 972/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4399e-04 - mae: 0.0134\n",
            "Epoch 973/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4235e-04 - mae: 0.0134\n",
            "Epoch 974/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4071e-04 - mae: 0.0133\n",
            "Epoch 975/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3908e-04 - mae: 0.0133\n",
            "Epoch 976/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3747e-04 - mae: 0.0132\n",
            "Epoch 977/1200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.3586e-04 - mae: 0.0132\n",
            "Epoch 978/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.3427e-04 - mae: 0.0131\n",
            "Epoch 979/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.3268e-04 - mae: 0.0131\n",
            "Epoch 980/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3113e-04 - mae: 0.0130\n",
            "Epoch 981/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2956e-04 - mae: 0.0130\n",
            "Epoch 982/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2802e-04 - mae: 0.0130\n",
            "Epoch 983/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2646e-04 - mae: 0.0129\n",
            "Epoch 984/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2494e-04 - mae: 0.0129\n",
            "Epoch 985/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2343e-04 - mae: 0.0128\n",
            "Epoch 986/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2191e-04 - mae: 0.0128\n",
            "Epoch 987/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2042e-04 - mae: 0.0127\n",
            "Epoch 988/1200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1893e-04 - mae: 0.0127\n",
            "Epoch 989/1200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.1746e-04 - mae: 0.0127\n",
            "Epoch 990/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.1599e-04 - mae: 0.0126\n",
            "Epoch 991/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1452e-04 - mae: 0.0126\n",
            "Epoch 992/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1308e-04 - mae: 0.0125\n",
            "Epoch 993/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1164e-04 - mae: 0.0125\n",
            "Epoch 994/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1020e-04 - mae: 0.0124\n",
            "Epoch 995/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0880e-04 - mae: 0.0124\n",
            "Epoch 996/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0738e-04 - mae: 0.0124\n",
            "Epoch 997/1200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0598e-04 - mae: 0.0123\n",
            "Epoch 998/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0459e-04 - mae: 0.0123\n",
            "Epoch 999/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0321e-04 - mae: 0.0122\n",
            "Epoch 1000/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0184e-04 - mae: 0.0122\n",
            "Epoch 1001/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0049e-04 - mae: 0.0122\n",
            "Epoch 1002/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9912e-04 - mae: 0.0121\n",
            "Epoch 1003/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9779e-04 - mae: 0.0121\n",
            "Epoch 1004/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9645e-04 - mae: 0.0120\n",
            "Epoch 1005/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9511e-04 - mae: 0.0120\n",
            "Epoch 1006/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9380e-04 - mae: 0.0119\n",
            "Epoch 1007/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9250e-04 - mae: 0.0119\n",
            "Epoch 1008/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9119e-04 - mae: 0.0119\n",
            "Epoch 1009/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8990e-04 - mae: 0.0118\n",
            "Epoch 1010/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8862e-04 - mae: 0.0118\n",
            "Epoch 1011/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8734e-04 - mae: 0.0117\n",
            "Epoch 1012/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8608e-04 - mae: 0.0117\n",
            "Epoch 1013/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8483e-04 - mae: 0.0117\n",
            "Epoch 1014/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8358e-04 - mae: 0.0116\n",
            "Epoch 1015/1200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.8234e-04 - mae: 0.0116\n",
            "Epoch 1016/1200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.8111e-04 - mae: 0.0116\n",
            "Epoch 1017/1200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.7988e-04 - mae: 0.0115\n",
            "Epoch 1018/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7867e-04 - mae: 0.0115\n",
            "Epoch 1019/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7747e-04 - mae: 0.0114\n",
            "Epoch 1020/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7626e-04 - mae: 0.0114\n",
            "Epoch 1021/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7507e-04 - mae: 0.0114\n",
            "Epoch 1022/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.7389e-04 - mae: 0.0113\n",
            "Epoch 1023/1200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.7272e-04 - mae: 0.0113\n",
            "Epoch 1024/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.7155e-04 - mae: 0.0112\n",
            "Epoch 1025/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7039e-04 - mae: 0.0112\n",
            "Epoch 1026/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6924e-04 - mae: 0.0112\n",
            "Epoch 1027/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6810e-04 - mae: 0.0111\n",
            "Epoch 1028/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6697e-04 - mae: 0.0111\n",
            "Epoch 1029/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6584e-04 - mae: 0.0111\n",
            "Epoch 1030/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6472e-04 - mae: 0.0110\n",
            "Epoch 1031/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6361e-04 - mae: 0.0110\n",
            "Epoch 1032/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6250e-04 - mae: 0.0109\n",
            "Epoch 1033/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6141e-04 - mae: 0.0109\n",
            "Epoch 1034/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.6032e-04 - mae: 0.0109\n",
            "Epoch 1035/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5924e-04 - mae: 0.0108\n",
            "Epoch 1036/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5816e-04 - mae: 0.0108\n",
            "Epoch 1037/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.5709e-04 - mae: 0.0108\n",
            "Epoch 1038/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.5603e-04 - mae: 0.0107\n",
            "Epoch 1039/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.5498e-04 - mae: 0.0107\n",
            "Epoch 1040/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5393e-04 - mae: 0.0106\n",
            "Epoch 1041/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.5290e-04 - mae: 0.0106\n",
            "Epoch 1042/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5186e-04 - mae: 0.0106\n",
            "Epoch 1043/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5084e-04 - mae: 0.0105\n",
            "Epoch 1044/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4982e-04 - mae: 0.0105\n",
            "Epoch 1045/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4880e-04 - mae: 0.0105\n",
            "Epoch 1046/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4780e-04 - mae: 0.0104\n",
            "Epoch 1047/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4680e-04 - mae: 0.0104\n",
            "Epoch 1048/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4581e-04 - mae: 0.0104\n",
            "Epoch 1049/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4483e-04 - mae: 0.0103\n",
            "Epoch 1050/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4385e-04 - mae: 0.0103\n",
            "Epoch 1051/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4289e-04 - mae: 0.0103\n",
            "Epoch 1052/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4191e-04 - mae: 0.0102\n",
            "Epoch 1053/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4096e-04 - mae: 0.0102\n",
            "Epoch 1054/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4001e-04 - mae: 0.0102\n",
            "Epoch 1055/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3906e-04 - mae: 0.0101\n",
            "Epoch 1056/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3812e-04 - mae: 0.0101\n",
            "Epoch 1057/1200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.3720e-04 - mae: 0.0101\n",
            "Epoch 1058/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3627e-04 - mae: 0.0100\n",
            "Epoch 1059/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3535e-04 - mae: 0.0100\n",
            "Epoch 1060/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3443e-04 - mae: 0.0100\n",
            "Epoch 1061/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3352e-04 - mae: 0.0099\n",
            "Epoch 1062/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3262e-04 - mae: 0.0099\n",
            "Epoch 1063/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3172e-04 - mae: 0.0099\n",
            "Epoch 1064/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3084e-04 - mae: 0.0098\n",
            "Epoch 1065/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2995e-04 - mae: 0.0098\n",
            "Epoch 1066/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2908e-04 - mae: 0.0098\n",
            "Epoch 1067/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2821e-04 - mae: 0.0097\n",
            "Epoch 1068/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2734e-04 - mae: 0.0097\n",
            "Epoch 1069/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2648e-04 - mae: 0.0097\n",
            "Epoch 1070/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2563e-04 - mae: 0.0096\n",
            "Epoch 1071/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2478e-04 - mae: 0.0096\n",
            "Epoch 1072/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.2394e-04 - mae: 0.0096\n",
            "Epoch 1073/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2310e-04 - mae: 0.0095\n",
            "Epoch 1074/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2227e-04 - mae: 0.0095\n",
            "Epoch 1075/1200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.2144e-04 - mae: 0.0095\n",
            "Epoch 1076/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2062e-04 - mae: 0.0094\n",
            "Epoch 1077/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1981e-04 - mae: 0.0094\n",
            "Epoch 1078/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1900e-04 - mae: 0.0094\n",
            "Epoch 1079/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1819e-04 - mae: 0.0093\n",
            "Epoch 1080/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1739e-04 - mae: 0.0093\n",
            "Epoch 1081/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1661e-04 - mae: 0.0093\n",
            "Epoch 1082/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1582e-04 - mae: 0.0092\n",
            "Epoch 1083/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1.1504e-04 - mae: 0.0092\n",
            "Epoch 1084/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.1427e-04 - mae: 0.0092\n",
            "Epoch 1085/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1349e-04 - mae: 0.0091\n",
            "Epoch 1086/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1272e-04 - mae: 0.0091\n",
            "Epoch 1087/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1196e-04 - mae: 0.0091\n",
            "Epoch 1088/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1121e-04 - mae: 0.0091\n",
            "Epoch 1089/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1046e-04 - mae: 0.0090\n",
            "Epoch 1090/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0971e-04 - mae: 0.0090\n",
            "Epoch 1091/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0897e-04 - mae: 0.0090\n",
            "Epoch 1092/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0823e-04 - mae: 0.0089\n",
            "Epoch 1093/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0750e-04 - mae: 0.0089\n",
            "Epoch 1094/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0677e-04 - mae: 0.0089\n",
            "Epoch 1095/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0606e-04 - mae: 0.0088\n",
            "Epoch 1096/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0534e-04 - mae: 0.0088\n",
            "Epoch 1097/1200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.0464e-04 - mae: 0.0088\n",
            "Epoch 1098/1200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.0392e-04 - mae: 0.0087\n",
            "Epoch 1099/1200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.0322e-04 - mae: 0.0087\n",
            "Epoch 1100/1200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.0252e-04 - mae: 0.0087\n",
            "Epoch 1101/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0183e-04 - mae: 0.0087\n",
            "Epoch 1102/1200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.0114e-04 - mae: 0.0086\n",
            "Epoch 1103/1200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.0046e-04 - mae: 0.0086\n",
            "Epoch 1104/1200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 9.9784e-05 - mae: 0.0086\n",
            "Epoch 1105/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.9111e-05 - mae: 0.0085\n",
            "Epoch 1106/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.8443e-05 - mae: 0.0085\n",
            "Epoch 1107/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 9.7775e-05 - mae: 0.0085\n",
            "Epoch 1108/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.7120e-05 - mae: 0.0085\n",
            "Epoch 1109/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.6457e-05 - mae: 0.0084\n",
            "Epoch 1110/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.5812e-05 - mae: 0.0084\n",
            "Epoch 1111/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 9.5159e-05 - mae: 0.0084\n",
            "Epoch 1112/1200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 9.4515e-05 - mae: 0.0083\n",
            "Epoch 1113/1200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 9.3880e-05 - mae: 0.0083\n",
            "Epoch 1114/1200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 9.3251e-05 - mae: 0.0083\n",
            "Epoch 1115/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.2624e-05 - mae: 0.0083\n",
            "Epoch 1116/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.1995e-05 - mae: 0.0082\n",
            "Epoch 1117/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.1374e-05 - mae: 0.0082\n",
            "Epoch 1118/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.0761e-05 - mae: 0.0082\n",
            "Epoch 1119/1200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.0145e-05 - mae: 0.0081\n",
            "Epoch 1120/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8.9535e-05 - mae: 0.0081\n",
            "Epoch 1121/1200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 8.8934e-05 - mae: 0.0081\n",
            "Epoch 1122/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.8331e-05 - mae: 0.0081\n",
            "Epoch 1123/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.7730e-05 - mae: 0.0080\n",
            "Epoch 1124/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.7144e-05 - mae: 0.0080\n",
            "Epoch 1125/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6555e-05 - mae: 0.0080\n",
            "Epoch 1126/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5971e-05 - mae: 0.0080\n",
            "Epoch 1127/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5392e-05 - mae: 0.0079\n",
            "Epoch 1128/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.4818e-05 - mae: 0.0079\n",
            "Epoch 1129/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.4238e-05 - mae: 0.0079\n",
            "Epoch 1130/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.3673e-05 - mae: 0.0079\n",
            "Epoch 1131/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.3105e-05 - mae: 0.0078\n",
            "Epoch 1132/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.2548e-05 - mae: 0.0078\n",
            "Epoch 1133/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.1987e-05 - mae: 0.0078\n",
            "Epoch 1134/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.1437e-05 - mae: 0.0077\n",
            "Epoch 1135/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.0890e-05 - mae: 0.0077\n",
            "Epoch 1136/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.0342e-05 - mae: 0.0077\n",
            "Epoch 1137/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.9795e-05 - mae: 0.0077\n",
            "Epoch 1138/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.9262e-05 - mae: 0.0076\n",
            "Epoch 1139/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.8724e-05 - mae: 0.0076\n",
            "Epoch 1140/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 7.8195e-05 - mae: 0.0076\n",
            "Epoch 1141/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.7665e-05 - mae: 0.0076\n",
            "Epoch 1142/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.7138e-05 - mae: 0.0075\n",
            "Epoch 1143/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.6619e-05 - mae: 0.0075\n",
            "Epoch 1144/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.6104e-05 - mae: 0.0075\n",
            "Epoch 1145/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.5590e-05 - mae: 0.0075\n",
            "Epoch 1146/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.5077e-05 - mae: 0.0074\n",
            "Epoch 1147/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.4570e-05 - mae: 0.0074\n",
            "Epoch 1148/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.4070e-05 - mae: 0.0074\n",
            "Epoch 1149/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.3569e-05 - mae: 0.0074\n",
            "Epoch 1150/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.3068e-05 - mae: 0.0073\n",
            "Epoch 1151/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2581e-05 - mae: 0.0073\n",
            "Epoch 1152/1200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2090e-05 - mae: 0.0073\n",
            "Epoch 1153/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.1598e-05 - mae: 0.0073\n",
            "Epoch 1154/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1119e-05 - mae: 0.0072\n",
            "Epoch 1155/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0642e-05 - mae: 0.0072\n",
            "Epoch 1156/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0159e-05 - mae: 0.0072\n",
            "Epoch 1157/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9685e-05 - mae: 0.0072\n",
            "Epoch 1158/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9220e-05 - mae: 0.0071\n",
            "Epoch 1159/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8749e-05 - mae: 0.0071\n",
            "Epoch 1160/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8288e-05 - mae: 0.0071\n",
            "Epoch 1161/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7821e-05 - mae: 0.0071\n",
            "Epoch 1162/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7373e-05 - mae: 0.0070\n",
            "Epoch 1163/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.6911e-05 - mae: 0.0070\n",
            "Epoch 1164/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6461e-05 - mae: 0.0070\n",
            "Epoch 1165/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.6012e-05 - mae: 0.0070\n",
            "Epoch 1166/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.5566e-05 - mae: 0.0069\n",
            "Epoch 1167/1200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.5125e-05 - mae: 0.0069\n",
            "Epoch 1168/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.4683e-05 - mae: 0.0069\n",
            "Epoch 1169/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.4244e-05 - mae: 0.0069\n",
            "Epoch 1170/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.3812e-05 - mae: 0.0069\n",
            "Epoch 1171/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3384e-05 - mae: 0.0068\n",
            "Epoch 1172/1200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2959e-05 - mae: 0.0068\n",
            "Epoch 1173/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.2527e-05 - mae: 0.0068\n",
            "Epoch 1174/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2109e-05 - mae: 0.0068\n",
            "Epoch 1175/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.1688e-05 - mae: 0.0067\n",
            "Epoch 1176/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.1275e-05 - mae: 0.0067\n",
            "Epoch 1177/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.0859e-05 - mae: 0.0067\n",
            "Epoch 1178/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.0450e-05 - mae: 0.0067\n",
            "Epoch 1179/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0040e-05 - mae: 0.0067\n",
            "Epoch 1180/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.9638e-05 - mae: 0.0066\n",
            "Epoch 1181/1200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.9230e-05 - mae: 0.0066\n",
            "Epoch 1182/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.8832e-05 - mae: 0.0066\n",
            "Epoch 1183/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.8435e-05 - mae: 0.0066\n",
            "Epoch 1184/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8040e-05 - mae: 0.0065\n",
            "Epoch 1185/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.7648e-05 - mae: 0.0065\n",
            "Epoch 1186/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7261e-05 - mae: 0.0065\n",
            "Epoch 1187/1200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 5.6870e-05 - mae: 0.0065\n",
            "Epoch 1188/1200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 5.6492e-05 - mae: 0.0065\n",
            "Epoch 1189/1200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6110e-05 - mae: 0.0064\n",
            "Epoch 1190/1200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5729e-05 - mae: 0.0064\n",
            "Epoch 1191/1200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5357e-05 - mae: 0.0064\n",
            "Epoch 1192/1200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.4982e-05 - mae: 0.0064\n",
            "Epoch 1193/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.4610e-05 - mae: 0.0063\n",
            "Epoch 1194/1200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.4240e-05 - mae: 0.0063\n",
            "Epoch 1195/1200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.3873e-05 - mae: 0.0063\n",
            "Epoch 1196/1200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.3509e-05 - mae: 0.0063\n",
            "Epoch 1197/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.3151e-05 - mae: 0.0063\n",
            "Epoch 1198/1200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.2789e-05 - mae: 0.0062\n",
            "Epoch 1199/1200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.2438e-05 - mae: 0.0062\n",
            "Epoch 1200/1200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.2081e-05 - mae: 0.0062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 훈련에 대한 결과가 저장된 history 변수를 사용하여 epoch 별 훈련 손실 및 평가 지표를 시각화해보자."
      ],
      "metadata": {
        "id": "lg7rw45q7h-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 20 epoch까지 Loss 수렴에 대한 시각화\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['mae'], label='mae')\n",
        "\n",
        "plt.xlim(-1, 20)\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "2F6durwi7nzN",
        "outputId": "edf1f6e3-7175-4b25-ddff-372b85729b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **2-9 검증**\n",
        "- 모델 인스턴스의 `evaluate()` 메서드로 모델의 성능을 검증할 수 있다.\n",
        "- 일반적으로 검증 데이터셋을 입력하여 진행한다.\n",
        "- 다만 이번 예제에서는 별도의 검증 데이터셋을 만들지 않았으므로, 훈련 데이터셋의 x, y를 대입하여 반환되는 결과를 확인한다."
      ],
      "metadata": {
        "id": "Fw8_mKZQiB7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증\n",
        "model.evaluate(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaGW3DRj8GEM",
        "outputId": "3e120dcf-c295-4bdc-e4a3-88d9ee4adbdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 136ms/step - loss: 5.1725e-05 - mae: 0.0062\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.172508463147096e-05, 0.006173038389533758]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **2-10 예측**\n",
        "- 훈련이 완료된 모델 인스턴스의 `predict()` 메소드에 새로운 입력 데이터를 넣어, 모델의 예측값을 입력해보자."
      ],
      "metadata": {
        "id": "VBtlPWK1iDSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측\n",
        "model.predict([10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGGXpr618OpM",
        "outputId": "028b948f-26ee-4298-d2f6-531dbcac38a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 165ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32.029835]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **03 심층신경망으로 이미지 분류**"
      ],
      "metadata": {
        "id": "EGaFkikshh5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **3-1 케라스 내장 데이터셋 로드**\n",
        "- 케라스는 모델 훈련에 필요한 샘플 데이터셋을 제공한다. 데이터셋은 `tensorflow.keras.datasets`에 위치한다.\n",
        "  - `bostion_housing` : 보스턴 주택 가격 데이터셋(회귀)\n",
        "  - `cifar10` : CIFAR10 이미지 분류 데이터셋(분류)\n",
        "  - `cifar100` : CIFAR100 이미지 분류 데이터셋(분류) \n",
        "  - `mnist` : mnist 손글씨 데이터셋(분류)\n",
        "  - `fashion_mnist` : 의류 데이터셋(분류)\n",
        "  - `imdb` : IMDb 영화 데이터셋(분류)\n",
        "  - `reuters` : Reuters 뉴스 토픽(분류)\n",
        "- 케라스의 datasets 패키지에 있는 데이터는 `load_data()` 메소드를 이용하여 불러올 수 있다.\n"
      ],
      "metadata": {
        "id": "5J_cylFliF60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 케라스의 내장 데이터셋에서 mnist 데이터셋을 로드\n",
        "mnist = tf.keras.datasets.mnist"
      ],
      "metadata": {
        "id": "73-QCgWbG2Vq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load_data()로 데이터셋을 로드\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APsNXewSG7y4",
        "outputId": "34c941ed-a504-4588-fd26-a6926b3c286a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 훈련 데이터셋과 검증 데이터셋의 크기를 확인해보자."
      ],
      "metadata": {
        "id": "P0ILzX_YHDb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 로드된 데이터셋 확인\n",
        "print('train set: ', x_train.shape, y_train.shape)\n",
        "print('test  set: ', x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl96f5D9HLjd",
        "outputId": "db5e5ad3-a02e-43e1-baff-56290157a057"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  (60000, 28, 28) (60000,)\n",
            "test  set:  (10000, 28, 28) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 훈련 데이터셋은 60,000개의 데이터가, 검증 데이터셋은 10,000개의 데이터가 저장되어 있다.\n",
        "- 28, 28은 이미지의 세로와 가로 픽셀 크기를 의미한다.\n",
        "- 이미지를 시각화해보자."
      ],
      "metadata": {
        "id": "gFY4AisqHM4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# canvas 생성\n",
        "fig, axes = plt.subplots(3, 5)\n",
        "fig.set_size_inches(8, 5)\n",
        "\n",
        "for i in range(15):\n",
        "    ax = axes[i//5, i%5]\n",
        "    # imshow로 이미지 시각화\n",
        "    ax.imshow(x_train[i], cmap='gray')\n",
        "    ax.axis('off')\n",
        "    ax.set_title(str(y_train[i]))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "LE7kElGuHfo_",
        "outputId": "3b1d867c-1ee3-410a-80f6-4e023992c7c2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 15 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **3-2 데이터 전처리**\n",
        "- 이미지 데이터에 대하여 정규화를 통해 데이터의 범위를 조절하자.\n",
        "- 배열의 각 원소는 이미지를 구성하는 하나의 픽셀값이다."
      ],
      "metadata": {
        "id": "_Pa2hkJUiNNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train 배열의 데이터 확인\n",
        "x_train[0, 10:15, 10:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E20FCteHt6e",
        "outputId": "ee1679db-c230-4fda-8328-9b349587a909"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1, 154, 253,  90,   0],\n",
              "       [  0, 139, 253, 190,   2],\n",
              "       [  0,  11, 190, 253,  70],\n",
              "       [  0,   0,  35, 241, 225],\n",
              "       [  0,   0,   0,  81, 240]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터가 0~1 사이의 값이 되도록 정규화한다."
      ],
      "metadata": {
        "id": "knLnP-GoHxJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 픽셀 값의 최소/최대 값 확인\n",
        "print(f'정규화 전] 최소값: {x_train.min()}, 최대값: {x_train.max()}')\n",
        "\n",
        "# 데이터 정규화\n",
        "x_train = x_train / x_train.max()\n",
        "\n",
        "# 정규화 후 최소/최대 값 확인\n",
        "print(f'정규화 후] 최소값: {x_train.min()}, 최대값: {x_train.max()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEW7YRt6H0Jr",
        "outputId": "7c96b143-b203-44d6-fe00-0143d9023877"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정규화 전] 최소값: 0, 최대값: 255\n",
            "정규화 후] 최소값: 0.0, 최대값: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 셋(검증셋)에도 정규화 동일 적용\n",
        "x_test = x_test / x_test.max()"
      ],
      "metadata": {
        "id": "zGJXZG8VH2BD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 변환 후 x_train 배열의 데이터 확인\n",
        "x_train[0, 10:15, 10:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2oqROJEH5aX",
        "outputId": "573b1209-047a-4d49-ae16-b1375a090766"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ],\n",
              "       [0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314],\n",
              "       [0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ],\n",
              "       [0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294],\n",
              "       [0.        , 0.        , 0.        , 0.31764706, 0.94117647]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **3-3 Flatten 레이어**\n",
        "- 정규화가 끝난 `x_train`의 크기는 여전히 (60000, 28, 28)이다.\n",
        "- 샘플 이미지의 형태는 (28, 28)로 2차원 입력 데이터로 볼 수 있다. 그러나 Dense 레이어는 2차원 데이터를 입력받지 못해, 다음과 같이 데이터를 1차원으로 변환해주어야 한다."
      ],
      "metadata": {
        "id": "_6nmxBDpiPI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'변경전 shape: {x_train.shape}')\n",
        "print(f'1D으로 shape 변경 후: {x_train.reshape(60000, -1).shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkMV2rNNIPei",
        "outputId": "cae07df5-64fa-4f3f-82ca-af15200f545a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "변경전 shape: (60000, 28, 28)\n",
            "1D으로 shape 변경 후: (60000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 또는 Flatten 레이어를 이용하여 1차원으로 만들어 줄 수도 있다."
      ],
      "metadata": {
        "id": "P7o0Od8OIO0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'변경전 shape: {x_train.shape}')\n",
        "\n",
        "# Flatten 레이어 적용 후 shape 확인\n",
        "print(f'Flatten 적용 후: {tf.keras.layers.Flatten()(x_train).shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD5446JAIbEJ",
        "outputId": "99df8b6b-f0a0-4c2e-d0fa-2d8d8f8e0b53"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "변경전 shape: (60000, 28, 28)\n",
            "Flatten 적용 후: (60000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **3-4 활성화 함수**\n",
        "- **활성화 함수(Activation Function)** : 입력을 비선형 출력으로 변환해주는 함수\n",
        "- 자주 사용되는 활성화 함수로는 시그모이드, tanh, ReLU, Leaky ReLU 등이 있다.\n",
        "- 아래와 같이 Dense 레이어에 ReLU 활성화 함수를 적용할 수 있다.\n",
        "```python\n",
        "# Dense 레이어에 relu 활성화 함수를 적용한 경우\n",
        "tf.keras.layers.Dense(128, activation='relu')\n",
        "```\n",
        "- 혹은 다음과 같이 별도의 클래스로 적용할 수도 있다.\n",
        "```python\n",
        "# Dense 레이어에 relu 활성화 함수를 적용한 경우\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128), \n",
        "    tf.keras.layers.Activation('relu')\n",
        "    ])\n",
        "```"
      ],
      "metadata": {
        "id": "ziBXtBOiiRNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **3-5 입력과 출력**\n",
        "- 딥러닝 모델을 만들 때는 첫 번째 레이어에 입력 데이터의 형태를 나타내는 `input_shape` 매개변수를 지정하는 것이 일반적이다.\n",
        "- 출력층의 노드 개수는 반드시 분류해야 할 클래스의 개수와 동일해야 한다. mnist의 경우 10개의 클래스로 이루어져 있으므로 마지막 출력층의 노드 개수는 10개이어야 한다."
      ],
      "metadata": {
        "id": "qJf7hoh0iS5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
        "    tf.keras.layers.Dense(256, activation='relu'), \n",
        "    tf.keras.layers.Dense(64, activation='relu'), \n",
        "    tf.keras.layers.Dense(32, activation='relu'), \n",
        "\n",
        "    # 노드=10개(클래스 개수와 동일)\n",
        "    tf.keras.layers.Dense(10, activation='softmax'), \n",
        "    ])"
      ],
      "metadata": {
        "id": "sUQP5nlKJSMK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 출력층의 노드 개수가 2개 이상인 경우, 즉 다중 분류 문제에서는 softmax 함수를 적용한다.\n",
        "- 이진 분류 모델의 출력층 노드 개수를 1개로 설정한 경우에는 sigmoid를 적용할 수 있다.\n",
        "```python\n",
        "# 출력층 노드 = 1인 경우, sigmoid\n",
        "tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "# 출력층 노드 = 2개 이상인 경우, softmax\n",
        "tf.keras.layers.Dense(10, activation='softmax')\n",
        "```"
      ],
      "metadata": {
        "id": "6QAGteziJXEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **3-6 손실함수**\n",
        "- 분류 모델의 손실 함수는 모델의 출력층에 따라 올바른 손실함수를 설정해야 모델이 정상적으로 훈련할 수 있다.\n",
        "- 출력 노드가 1개, sigmoid 활성화 함수를 적용한 경우\n",
        "```python\n",
        "# 이진 분류 (출력 노드 개수 = 1, sigmoid 인 경우)\n",
        "model.compile(loss='binary_crossentropy')\n",
        "```\n",
        "- 출력 노드가 2개 이상, softmax 활성화 함수를 적용한 경우\n",
        "```python\n",
        "# y가 원 핫 벡터인 경우\n",
        "# [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]\n",
        "model.compile(loss='categorical_crossentropy')\n",
        "# y가 원 핫 벡터가 아닌경우\n",
        "# [5]\n",
        "model.compile(loss='sparse_categorical_crossentropy')\n",
        "```"
      ],
      "metadata": {
        "id": "P8XEAo0siUoy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **3-7 옵티마이저**\n",
        "- **옵티마이저(optimizer)** : 손실을 낮추기 위해서, 신경망의 가중치와 학습률과 같은 신경망의 속성을 변경하는 데 사용되는 최적화 방법\n",
        "- 일반적으로 Adam이 많이 사용된다.\n",
        "- 케라스에서 지원하는 옵티마이저 : SGD, Adam, Adagrad, Nadam, RMSprop, Adadelta, Adamax, Ftrl\n",
        "- 다음과 같이 옵티마이저를 지정할 수 있다.\n",
        "```python\n",
        "# 클래스 인스턴스로 지정\n",
        "adam = tf.keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(optimizer=adam)\n",
        "# 문자열로 지정\n",
        "model.compile(optimizer='adam')\n",
        "```"
      ],
      "metadata": {
        "id": "v09EUQ-NiWQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **3-8 평가지표**\n",
        "- 분류 모델에 대한 평가 지표 : 정확도(`accuracy`), `auc`, `precision`, `recall` 등\n",
        "- metrics 매개변수에 파이썬 리스트 형태로 하나 이상의 평가지표를 지정하여 여러 지표들을 동시에 참고할 수 있다."
      ],
      "metadata": {
        "id": "mcr3_uWQiYJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 인스턴스로 지정\n",
        "acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=[acc])"
      ],
      "metadata": {
        "id": "xGU1hyJEQms9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열로 지정\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BbTm-TIKQfyy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **3-9 훈련**\n",
        "- 모델을 훈련할 때 검증 데이터셋을 추가로 지정한다. \n",
        "- 매 epoch마다 훈련 손실과 검증 손실, 각 데이터셋에 대한 평가지표를 나란히 출력한다."
      ],
      "metadata": {
        "id": "ONqSMlyGiaA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련\n",
        "model.fit(x_train, y_train,       \n",
        "          validation_data=(x_test, y_test), # 검증셋 지정\n",
        "          epochs=10, \n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilfW_eFtQ2SF",
        "outputId": "d3b84e03-003b-4504-f457-e2ef0cd96a1b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2362 - sparse_categorical_accuracy: 0.9302 - val_loss: 0.1270 - val_sparse_categorical_accuracy: 0.9608\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0989 - sparse_categorical_accuracy: 0.9698 - val_loss: 0.0887 - val_sparse_categorical_accuracy: 0.9727\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0794 - val_sparse_categorical_accuracy: 0.9763\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0493 - sparse_categorical_accuracy: 0.9848 - val_loss: 0.0834 - val_sparse_categorical_accuracy: 0.9750\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0412 - sparse_categorical_accuracy: 0.9866 - val_loss: 0.0805 - val_sparse_categorical_accuracy: 0.9776\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0325 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.0830 - val_sparse_categorical_accuracy: 0.9777\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0278 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0808 - val_sparse_categorical_accuracy: 0.9769\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0231 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0956 - val_sparse_categorical_accuracy: 0.9779\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0227 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0861 - val_sparse_categorical_accuracy: 0.9779\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0186 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.1010 - val_sparse_categorical_accuracy: 0.9789\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7c291d2f50>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **3-10 평가**\n",
        "- 10회의 epoch이 끝나고 훈련이 종료된 뒤, `evaluate()` 메서드로 모델을 검증하고 평가 결과를 확인할 수 있다.\n",
        "- 이때, 검증 데이터셋을 이용한다."
      ],
      "metadata": {
        "id": "VUqKnJ_mibWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test)\n",
        "\n",
        "print('검증셋 정확도:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMAoI5O0Rcl5",
        "outputId": "59f8b04a-118b-426d-ab0e-559572ee759a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1010 - sparse_categorical_accuracy: 0.9789\n",
            "검증셋 정확도: 0.9789000153541565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **3-11 예측**\n",
        "- 훈련된 모델로 새로운 이미지에 대한 분류 값을 예측할 수 있다.\n",
        "- `predict()` 메서드를 이용한다."
      ],
      "metadata": {
        "id": "gqao8Byhict_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측\n",
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1fdjX4zRlbN",
        "outputId": "2cbcbeb1-1dff-4d69-cb18-0a4e73c0e648"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 결과 출력\n",
        "predictions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp7G6eJQRmq_",
        "outputId": "4032d748-1e0f-429b-fe0d-161985f71097"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.0893552e-12, 4.1164228e-07, 1.0683686e-08, 2.4297886e-10,\n",
              "       3.8475028e-09, 6.3633508e-11, 8.4217123e-15, 9.9999958e-01,\n",
              "       2.9689817e-10, 5.3783516e-08], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 넘파이의 `argmax`를 이용해 가장 높은 확률값을 가지는 클래스를 확인해볼 수 있다."
      ],
      "metadata": {
        "id": "3bd_krmpRsLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 0번 index에 대한 예측 클래스 출력\n",
        "print(np.argmax(predictions[0]))\n",
        "\n",
        "# 첫 10개 index에 대한 예측 클래스 출력\n",
        "print(np.argmax(predictions[:10], axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEVhmcKhRplr",
        "outputId": "f7c57a6c-9b64-4c1d-c42a-e49637bf39f9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "[7 2 1 0 4 1 4 9 5 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 예측한 결과를 시각화해보자."
      ],
      "metadata": {
        "id": "Jtuc-tIERxlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_one_result(idx):\n",
        "    img, y_true, y_pred, confidence = x_test[idx], y_test[idx], np.argmax(predictions[idx]), 100*np.max(predictions[idx])\n",
        "    return img, y_true, y_pred, confidence\n",
        "    \n",
        "# canvas 생성\n",
        "fig, axes = plt.subplots(3, 5)\n",
        "fig.set_size_inches(12, 10)\n",
        "\n",
        "for i in range(15):\n",
        "    ax = axes[i//5, i%5]\n",
        "\n",
        "    img, y_true, y_pred, confidence = get_one_result(i)\n",
        "\n",
        "    # imshow로 이미지 시각화\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_title(f'True: {y_true}')\n",
        "    ax.set_xlabel(f'Prediction: {y_pred}\\nConfidence: ({confidence:.2f} %)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "E7qcr13wR0ZS",
        "outputId": "083e1714-e078-4720-a8e3-b3c43af0940e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x720 with 15 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **04 모델 세부 설정**"
      ],
      "metadata": {
        "id": "3D9-igc0hkk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 케라스의 내장 데이터셋에서 mnist 데이터셋을 로드\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# load_data()로 데이터셋을 로드\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 로드된 데이터셋 확인\n",
        "print('train set: ', x_train.shape, y_train.shape)\n",
        "print('test  set: ', x_test.shape, y_test.shape)\n",
        "\n",
        "# 데이터 정규화\n",
        "x_train = x_train / x_train.max() # max: 255\n",
        "x_test = x_test / x_test.max() # max: 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9jy6vZXR5As",
        "outputId": "0e005721-ac28-4b27-cfe2-531f357293e6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  (60000, 28, 28) (60000,)\n",
            "test  set:  (10000, 28, 28) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **4-1 초기값 설정**\n",
        "- 레이어의 초기화 방법을 다르게 설정할 수 있다.\n",
        "- Dense 레이어는 기본값으로 Glorot Uniform 초기화 방법이 설정되어 있다."
      ],
      "metadata": {
        "id": "jGQ5urS_ieUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense = tf.keras.layers.Dense(256, activation='relu')\n",
        "dense.get_config()['kernel_initializer']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APfdbQdeSH_y",
        "outputId": "50a15248-ff44-4ddc-d0b8-08aba9de27f7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class_name': 'GlorotUniform', 'config': {'seed': None}}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `kernal_initializer` 매개변수를 설정하면 초기화 방법을 변경할 수 있다.\n",
        "- 역시 옵티마이저나 손실함수처럼 문자열로 지정하거나 클래스 인스턴스로 지정할 수 있다."
      ],
      "metadata": {
        "id": "ZIUpE04KSJRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열 초기화\n",
        "dense = tf.keras.layers.Dense(256, kernel_initializer='he_normal', activation='relu')\n",
        "print(dense.get_config()['kernel_initializer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JmKHUjYSS04",
        "outputId": "30459635-e856-41e4-b552-84f82acd84c2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'class_name': 'HeNormal', 'config': {'seed': None}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 인스턴스 초기화\n",
        "he_normal = tf.keras.initializers.HeNormal()\n",
        "dense = tf.keras.layers.Dense(256, kernel_initializer=he_normal, activation='relu')\n",
        "print(dense.get_config()['kernel_initializer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_ouQoq6SX6s",
        "outputId": "249ffaeb-2cb4-48a6-fc1c-4df4ca9e0742"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'class_name': 'HeNormal', 'config': {'seed': None}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **4-2 규제(Regularization)**\n",
        "- 모델의 과대적합을 해소하기 위해 L1, L2 규제를 적용하기도 한다.\n",
        "- `kernel_regularizer`를 설정하여 적용할 수 있다."
      ],
      "metadata": {
        "id": "0vC1vjZXihPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 값\n",
        "dense = tf.keras.layers.Dense(256, activation='relu')\n",
        "dense.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcI_x0eFSk0f",
        "outputId": "8bb95efe-13be-4760-b5ec-9512d24812f9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'dense_10',\n",
              " 'trainable': True,\n",
              " 'dtype': 'float32',\n",
              " 'units': 256,\n",
              " 'activation': 'relu',\n",
              " 'use_bias': True,\n",
              " 'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "  'config': {'seed': None}},\n",
              " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              " 'kernel_regularizer': None,\n",
              " 'bias_regularizer': None,\n",
              " 'activity_regularizer': None,\n",
              " 'kernel_constraint': None,\n",
              " 'bias_constraint': None}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# l1 규제 적용\n",
        "dense = tf.keras.layers.Dense(256, kernel_regularizer='l1', activation='relu')\n",
        "print(dense.get_config()['kernel_regularizer'])\n",
        "\n",
        "# 클래스 인스턴스 적용, alpha 값 변경\n",
        "regularizer = tf.keras.regularizers.l1(l1=0.1)\n",
        "dense = tf.keras.layers.Dense(256, kernel_regularizer=regularizer, activation='relu')\n",
        "print(dense.get_config()['kernel_regularizer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4rP6jfkSmaO",
        "outputId": "c4930084-0e01-49a0-b38e-91800073e127"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'class_name': 'L1', 'config': {'l1': 0.009999999776482582}}\n",
            "{'class_name': 'L1', 'config': {'l1': 0.10000000149011612}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **4-3 드롭아웃(Dropout)**\n",
        "- 딥러닝 모델은 층이 넓고 깊어질 때, 과대적합 문제가 발생하는데 드롭아웃은 이 문제를 해결하기 위해 제안된 아이디어로, 상당히 좋은 효과를 보이고 있다.\n",
        "- 노드의 일부 신호를 임의로 삭제하여, 모델이 학습하는 가중치 파라미터의 개수를 줄이는 방식이다."
      ],
      "metadata": {
        "id": "FUhybQgPikPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropout 25% 비율 적용 (25%의 노드가 삭제)\n",
        "tf.keras.layers.Dropout(0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNQzJpT1S74J",
        "outputId": "e680723b-9f35-47af-e305-e2c9ae703dc7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.regularization.dropout.Dropout at 0x7f7c27d29490>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **4-4 배치 정규화(Batch Normalization)**\n",
        "- 배치 정규화는 각 층에서 활성화 함수를 통과하기 전, 미니 배치의 스케일을 정규화한다.\n",
        "- 보다 안정적인 훈련이 가능하고, 성능을 크게 향상시킬 수 있다.\n",
        "- 배치 정규화를 적용하지 않은 모델을 `model_a`, 적용한 모델을 `model_b`로 지정하여 성능 비교를 해보자."
      ],
      "metadata": {
        "id": "LHSodOmMim4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model A: Dense + ReLU\n",
        "model_a = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "model_a.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFKNZcboTVS3",
        "outputId": "85449b6e-be86-4c5d-c2ed-4b55e2b890e7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52,650\n",
            "Trainable params: 52,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model B: Dense + BatchNorm + ReLU\n",
        "model_b = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(64),\n",
        "    # 배치정규화 적용\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # 배치정규화 후 활성화 함수 적용\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(32),\n",
        "    # 배치정규화 적용\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # 배치정규화 후 활성화 함수 적용\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "model_b.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmqHnhAFTXM7",
        "outputId": "6c5318b6-082e-41dd-cc68-ea875ae11d87"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 64)                50240     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 64)               256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53,034\n",
            "Trainable params: 52,842\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### | **4-5 활성화(activation) 함수**\n",
        "- 다음과 같이 클래스 인스턴스로 선언하면, 활성화 함수의 하이퍼파라미터 값을 변경하여 적용할 수 있다."
      ],
      "metadata": {
        "id": "mscJ1fOemYLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LeakyReLU 기본 설정\n",
        "tf.keras.layers.LeakyReLU()\n",
        "\n",
        "# LeakyReLU, alpha=0.2 로 변경\n",
        "tf.keras.layers.LeakyReLU(alpha=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M7FOV0DToh6",
        "outputId": "1c3037ad-5dfa-4fff-c023-7bcefdd48084"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.activation.leaky_relu.LeakyReLU at 0x7f7c279174d0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model C: Dense + BatchNorm + LeakyReLU(0.2)\n",
        "model_c = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(64),\n",
        "    # 배치정규화 적용\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # LeakyReLU, alpha=0.2 적용\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "\n",
        "    tf.keras.layers.Dense(32),\n",
        "    # 배치정규화 적용\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # LeakyReLU, alpha=0.2 적용\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "\n",
        "    tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# 모델 요약\n",
        "model_c.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0vmBS1MTqPb",
        "outputId": "b8a87715-5346-46f8-e4e5-9a25611d5e8b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 64)                50240     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 64)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 32)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53,034\n",
            "Trainable params: 52,842\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 앞에서 생성한 2개의 모델과 LeakyReLU 활성화 함수로 변경한 모델을 동일한 조건으로 10 epoch 훈련한 후, 수렴 속도를 확인해보자."
      ],
      "metadata": {
        "id": "zk1eyd-wTtaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_a.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_b.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_c.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model A: Dense + ReLU\n",
        "history_a = model_a.fit(x_train, y_train, \n",
        "                        validation_data=(x_test, y_test), \n",
        "                        epochs=10)\n",
        "\n",
        "# Model B: Dense + BatchNorm + ReLU\n",
        "history_b = model_b.fit(x_train, y_train, \n",
        "                        validation_data=(x_test, y_test), \n",
        "                        epochs=10)\n",
        "\n",
        "# Model C: Dense + BatchNorm + LeakyReLU(0.2)\n",
        "history_c = model_c.fit(x_train, y_train, \n",
        "                        validation_data=(x_test, y_test), \n",
        "                        epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDMU7I97T1vi",
        "outputId": "ba8b7410-e5b1-4422-e7ea-adfd9ff8d48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2920 - accuracy: 0.9148 - val_loss: 0.1659 - val_accuracy: 0.9496\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1343 - accuracy: 0.9595 - val_loss: 0.1335 - val_accuracy: 0.9599\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0977 - accuracy: 0.9703 - val_loss: 0.1015 - val_accuracy: 0.9682\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0779 - accuracy: 0.9763 - val_loss: 0.0956 - val_accuracy: 0.9694\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0660 - accuracy: 0.9795 - val_loss: 0.0941 - val_accuracy: 0.9714\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0562 - accuracy: 0.9825 - val_loss: 0.0910 - val_accuracy: 0.9717\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0478 - accuracy: 0.9847 - val_loss: 0.0951 - val_accuracy: 0.9745\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0435 - accuracy: 0.9861 - val_loss: 0.0989 - val_accuracy: 0.9724\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.1028 - val_accuracy: 0.9729\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0343 - accuracy: 0.9887 - val_loss: 0.0880 - val_accuracy: 0.9767\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3271 - accuracy: 0.9111 - val_loss: 0.1338 - val_accuracy: 0.9599\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1459 - accuracy: 0.9567 - val_loss: 0.1024 - val_accuracy: 0.9691\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1112 - accuracy: 0.9660 - val_loss: 0.0915 - val_accuracy: 0.9709\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0952 - accuracy: 0.9694 - val_loss: 0.0854 - val_accuracy: 0.9725\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0847 - accuracy: 0.9734 - val_loss: 0.0867 - val_accuracy: 0.9735\n",
            "Epoch 6/10\n",
            "  31/1875 [..............................] - ETA: 6s - loss: 0.0860 - accuracy: 0.9728"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(12, 9))\n",
        "plt.plot(np.arange(1, 11), history_a.history['val_loss'], color='navy', linestyle=':')\n",
        "plt.plot(np.arange(1, 11), history_b.history['val_loss'], color='tomato', linestyle='-.')\n",
        "plt.plot(np.arange(1, 11), history_c.history['val_loss'], color='green', linestyle='-')\n",
        "\n",
        "plt.title('Losses', fontsize=20)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Losses')\n",
        "plt.legend(['ReLU', 'BatchNorm + ReLU','batchnorm + LeakyReLU'], fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ptZvnC5ZT3kQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}